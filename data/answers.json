[{"question":[{"txt":"An administrator wants to receive an environment summary report when a host failure occurs. Which action would address the administrator’s need? "}],"options":["Enable App Discovery ","Edit report schedule ","Configure an alert policy","Create a playbook "],"goodAnswer":[2],"explanations":[{"txt":"L'option A, \"Enable App Discovery\", n'est pas pertinente car elle concerne la découverte des applications, pas la réception de rapports lorsqu'une défaillance d'hôte se produit."},{"txt":"L'option B, \"Edit report schedule\", ne répond pas spécifiquement au besoin de recevoir un rapport lorsqu'une défaillance d'hôte se produit. Cela concerne plutôt la modification de la planification des rapports existants."},{"txt":"L'option D, \"Create a playbook\", est également incorrecte car la création d'un playbook est généralement associée à des tâches automatisées pour la gestion et la résolution des incidents, pas spécifiquement à la réception de rapports lorsqu'une défaillance d'hôte se produit."},{"txt":"L'option correcte, C, \"Configure an alert policy\", permet à l'administrateur de définir des règles d'alerte pour recevoir des notifications lorsque des événements spécifiques se produisent dans l'environnement, tels que la défaillance d'un hôte. En configurant une politique d'alerte appropriée, l'administrateur peut s'assurer de recevoir un rapport ou une notification dès qu'une défaillance d'hôte se produit, répondant ainsi à son besoin."},{"img":"1710520726391.png"}],"id":1},{"question":[{"txt":"An administrator has been notified by à user that a Microsoft SQL Server instance is not performing well. \nWhen reviewing the utilization metrics, the following concerns are noted: \nMemory consumption has been above 95% for several months \nMemory consumption has been spiking to 100% for the last five days \nStorage latency is 2ms. \nWhen logging into Prism Central, how could the administrator quickly verify if this VM has performance bottlenecks? "}],"options":["See Capacity Runway. ","Filter VM by Efficiency. "," Update Capacity Configurations. ","Perform Entity Sync "],"goodAnswer":[0],"explanations":[{"txt":"A. Voir la capacité de piste.\n\nLa capacité de piste (Capacity Runway) dans Nutanix est un outil d'analyse prédictive qui permet aux administrateurs de prévoir quand l'espace de stockage disponible pourrait être épuisé en fonction des tendances de croissance actuelles. Si la mémoire est constamment au-dessus de 95% et a atteint 100% récemment, cela pourrait indiquer une utilisation intensive des ressources, ce qui affecterait la capacité de piste.\nB. Filtrer les VM par efficacité.\n\nCela semble moins pertinent dans ce contexte. Filtrer les VM par efficacité pourrait aider à identifier les machines virtuelles qui utilisent les ressources de manière inefficace, mais cela ne donnerait pas une vue d'ensemble immédiate des goulets d'étranglement de performance.\nC. Mettre à jour les configurations de capacité.\n\nCeci est également moins pertinent dans ce contexte. Mettre à jour les configurations de capacité peut être nécessaire à un moment donné pour optimiser les ressources, mais cela ne résoudrait pas directement le problème immédiat de goulot d'étranglement de performance de la VM SQL Server.\nD. Effectuer une synchronisation d'entité.\n\nCela concerne la synchronisation des données entre différents composants de l'infrastructure Nutanix. Cela n'apporterait pas d'informations directes sur les performances de la VM SQL Server.\nDans ce cas, la réponse la plus pertinente est A, voir la capacité de piste. Cela permettrait à l'administrateur de comprendre si la VM a des goulets d'étranglement de performance en surveillant l'utilisation des ressources et en prévoyant la disponibilité future de l'espace de stockage."}],"id":2},{"question":[{"txt":"Which Nutanix service controls ncli, the HTML5 UI, and Rest API?"}],"options":["Prism","Cassandra","Zookeeper","Chronos"],"goodAnswer":[0],"explanations":[{"txt":"La réponse à cette question est A. Prism.\n\nPrism est la solution de gestion de cluster de Nutanix. Il offre une interface utilisateur basée sur HTML5 (HTML5 UI) pour la gestion et la surveillance des clusters Nutanix. Prism fournit également un accès à l'API REST pour automatiser et intégrer des tâches de gestion avec d'autres systèmes. De plus, Prism est responsable de la gestion de l'interface en ligne de commande Nutanix (Nutanix Command Line Interface - ncli), ce qui permet aux administrateurs d'exécuter des commandes pour configurer et gérer leurs clusters Nutanix.\n\nLes autres options ne sont pas directement associées au contrôle de ncli, de l'interface utilisateur HTML5 ou de l'API REST dans le contexte de la gestion des clusters Nutanix :\n\nB. Cassandra est une base de données distribuée largement utilisée, mais elle n'est pas spécifiquement liée à la gestion de l'interface utilisateur ou de l'API de Nutanix.\nC. Zookeeper est un service de coordination distribué pour les applications distribuées, mais il n'est pas utilisé pour contrôler spécifiquement l'interface utilisateur ou l'API de Nutanix.\nD. Chronos est un planificateur de tâches distribué utilisé avec le système de gestion de cluster Mesos, mais il n'est pas associé à la gestion des clusters Nutanix ou de ses interfaces."}],"id":3},{"question":[{"txt":"On a Nutanix cluster, what does Network Segmentation refer to?"}],"options":[" A distributed firewall for securing VM-to-VM traffic.","Physically separating management traffic from guest VM traffic."," Isolating intra-cluster traffic from guest VM traffic.","Isolating management traffic from storage replication traffic."],"goodAnswer":[3],"explanations":[{"txt":"La réponse à cette question est D. Isoler le trafic de gestion du trafic de réplication de stockage.\n\nLa segmentation réseau sur un cluster Nutanix fait référence à l'isolation du trafic de gestion du trafic de réplication de stockage. Cela signifie que le trafic de gestion, tel que celui destiné aux opérations de gestion et de surveillance du cluster, est séparé du trafic de réplication de stockage, qui implique le transfert de données entre les nœuds du cluster pour maintenir la redondance et la disponibilité des données.\n\nCela permet d'optimiser les performances et la disponibilité du cluster en garantissant que le trafic de gestion critique n'est pas affecté par le trafic de réplication intensif. De plus, cela peut contribuer à renforcer la sécurité et à améliorer la gestion du réseau dans l'environnement Nutanix.\n\nLes autres options ne correspondent pas à la définition de la segmentation réseau sur un cluster Nutanix :\n\nA. Un pare-feu distribué pour sécuriser le trafic VM-à-VM ne correspond pas à la définition de la segmentation réseau sur un cluster Nutanix, bien qu'il puisse être une mesure de sécurité supplémentaire.\nB. La séparation physique du trafic de gestion du trafic des VM invitées n'est pas ce que l'on entend généralement par segmentation réseau sur un cluster Nutanix.\nC. Isoler le trafic intra-cluster du trafic des VM invitées ne correspond pas à la définition habituelle de la segmentation réseau sur un cluster Nutanix."}],"id":4},{"question":[{"txt":"An administrator has an AHV cluster that is comprised of 4 nodes with the following configuration in each node:\n\nCPU: 2 each 2.4GHz, 12 cores\nMemory: 256GB\nDisk: 6 each 1.92 SSD\nA VM with 16 vCPUs and 96GB of RAM is being created on the cluster. How should the administrator configure the VM to assure optimal performance?\n"}],"options":["With an affinity policy","With memory overcommit","With 2 vNUMA node","With Flash Mode enabled"],"goodAnswer":[2],"explanations":[{"txt":"La réponse à cette question est C. Avec 2 nœuds vNUMA (Virtual Non-Uniform Memory Access).\n\nPour assurer des performances optimales de la machine virtuelle (VM) sur le cluster Nutanix AHV, il est important de comprendre comment la configuration de la VM correspond à la configuration matérielle sous-jacente.\n\nDans ce cas, la configuration des nœuds du cluster est la suivante :\n\nCPU : 2 processeurs, chacun avec 2.4 GHz et 12 cœurs\nMémoire : 256 Go\nDisque : 6 SSD de 1.92 To chacun\nLa VM en question a 16 vCPU et 96 Go de RAM.\n\nPour obtenir des performances optimales, il est recommandé d'aligner la configuration de la VM sur la configuration physique du matériel. L'utilisation de 2 nœuds vNUMA permet de s'assurer que la VM tire pleinement parti de la disposition matérielle des cœurs de processeur et de la mémoire.\nhttps://portal.nutanix.com/page/documents/solutions/details?targetId=BP-2029-AHV:virtual-nonuniform-memory-access-and-guest-vms.html\n\nLes autres options ne correspondent pas à des considérations directes pour optimiser les performances de la VM sur le cluster AHV de Nutanix :\n\nA. Une politique d'affinité peut aider à contrôler sur quel nœud physique une VM est exécutée, mais cela ne garantit pas nécessairement des performances optimales.\nB. Le sur-engagement de mémoire (memory overcommit) pourrait être risqué dans ce cas, car la VM a déjà une allocation de mémoire substantielle par rapport à la capacité physique disponible.\nD. Activer le mode Flash (Flash Mode) concerne le stockage et ne jouerait pas un rôle direct dans l'optimisation des performances de la VM en termes de CPU et de mémoire."}],"id":5},{"question":[{"txt":"An administrator needs to limit the amount of storage space that data stored in single container can consume. \nWhich action should the administrator take? "}],"options":["Enable reservation for rebuild capacity ","Set an advertised capacity for the container","Store VM snapshots in a different container ","Thick prevision the container "],"goodAnswer":[1],"explanations":[{"txt":"La réponse à cette question est B. Définir une capacité annoncée pour le conteneur.\n\nLorsqu'un administrateur souhaite limiter la quantité d'espace de stockage qu'un conteneur individuel peut consommer, la meilleure approche est de définir une capacité annoncée pour ce conteneur. Cela permet de spécifier explicitement la quantité maximale de stockage que le conteneur est autorisé à utiliser.\n\nLes autres options ne correspondent pas à des actions visant à limiter la quantité d'espace de stockage utilisée par un conteneur spécifique :\n\nA. Activer la réservation pour la capacité de reconstruction (Enable reservation for rebuild capacity) concerne la gestion de la capacité de reconstruction dans un cluster Nutanix. Cela n'est pas directement lié à la limitation de l'espace de stockage pour un conteneur individuel.\nC. Stocker les instantanés de machines virtuelles dans un conteneur différent (Store VM snapshots in a different container) n'est pas une méthode directe pour limiter l'espace de stockage utilisé par un conteneur spécifique. Bien que cela puisse être une bonne pratique pour la gestion des instantanés, cela ne répond pas à la question posée.\nD. Le provisionnement épais du conteneur (Thick provision the container) implique de réserver immédiatement l'espace disque nécessaire pour un conteneur lors de sa création. Cependant, cela ne limite pas explicitement la quantité d'espace de stockage que le conteneur peut consommer au fil du temps."}],"id":6},{"question":[{"txt":"An administrator needs to configure Prism to send encrypted messages to a set of recipients.\nWhich setting must be applied?"}],"options":["Use SMTP Port 25","Configure Prism Central to use Cluster Lockdown","Install SSL certificates on Prism Central","Set SMTP Security Mode to STARTTLS"],"goodAnswer":[3],"explanations":[{"txt":"La réponse à cette question est D. Configurer le mode de sécurité SMTP sur STARTTLS.\n\nLe protocole STARTTLS (Transport Layer Security) permet de sécuriser les communications SMTP (Simple Mail Transfer Protocol) en les chiffrant. En configurant Prism pour utiliser STARTTLS, les messages envoyés depuis Prism vers les destinataires seront cryptés, assurant ainsi la confidentialité des informations transmises.\n\nLes autres options ne sont pas directement liées à la sécurisation des messages envoyés depuis Prism :\n\nA. Utiliser le port SMTP 25 (SMTP Port 25) est une configuration standard pour le protocole SMTP, mais cela ne garantit pas que les messages seront cryptés.\nB. Configurer Prism Central pour utiliser le verrouillage de cluster (Cluster Lockdown) est une mesure de sécurité pour restreindre l'accès au cluster, mais cela ne concerne pas spécifiquement le chiffrement des messages envoyés par Prism.\nC. Installer des certificats SSL sur Prism Central (Install SSL certificates on Prism Central) est important pour sécuriser les communications avec Prism, mais cela ne garantit pas que les messages seront cryptés lorsqu'ils sont envoyés à des destinataires."}],"id":7},{"question":[{"txt":"Which two permission assignment tasks can be accomplished via Prism Element? (Choose two.)"}],"options":["Grant a user permission to create VMs on a specific storage container","Grant a user permission to view details of all VMs on a specific cluster","Grant an active directory group permission to perform back operations","Grant a user permission to create and delete snapshots on a specific VM"],"goodAnswer":[0,3],"explanations":[{"txt":"La réponse correcte est A. Accorder à un utilisateur la permission de créer des VM sur un conteneur de stockage spécifique et D. Accorder à un utilisateur la permission de créer et de supprimer des instantanés sur une VM spécifique.\n\nExplication :\n\nA. Accorder à un utilisateur la permission de créer des VM sur un conteneur de stockage spécifique : Cette tâche peut être réalisée via Prism Element en attribuant des autorisations spécifiques à cet utilisateur pour le conteneur de stockage concerné.\n\nD. Accorder à un utilisateur la permission de créer et de supprimer des instantanés sur une VM spécifique : Prism Element permet de gérer les instantanés des VM au niveau du cluster, y compris la création et la suppression d'instantanés spécifiques à une VM.\n\nLes autres options ne correspondent pas aux tâches généralement gérées par Prism Element :\n\nB. Accorder à un utilisateur la permission de voir les détails de toutes les VM sur un cluster spécifique : Bien que Prism Element permette la visualisation des détails des VM sur un cluster, la gestion des autorisations pour cela est souvent associée à Prism Central, qui gère les opérations globales de gestion des clusters.\n\nC. Accorder à un groupe Active Directory la permission d'effectuer des opérations de sauvegarde : La gestion des autorisations pour les opérations de sauvegarde est souvent gérée au niveau de Prism Central, plutôt qu'au niveau de Prism Element, qui est plus centré sur la gestion des ressources au niveau du cluster."}],"id":8},{"question":[{"txt":"In the event of a disk failure, which process will immediately ad automatically scans Cassandra to find all data previously hosted on the failed disk, and all disks in that node?"}],"options":["Curator","Stargate","Genesis","Prism"],"goodAnswer":[0],"explanations":[{"txt":"En cas de défaillance d'un disque dans un environnement Nutanix, le processus responsable de scanner automatiquement Cassandra pour trouver toutes les données précédemment hébergées sur le disque défaillant, ainsi que tous les disques dans ce nœud, est le processus Curator.\n\nCurator est chargé de la gestion du système de fichiers distribué (DFS) dans les clusters Nutanix. Il intervient également dans la gestion des données et assure leur intégrité et leur disponibilité. Lorsqu'un disque échoue, Curator intervient pour identifier les données précédemment hébergées sur ce disque et sur tous les autres disques du même nœud. Cela garantit une reprise rapide et automatisée en cas de défaillance du disque.\n\nDonc, la bonne réponse est :\n\nA. Curator"}],"id":9},{"question":[{"txt":"An Administrator has been asked to deploy VMs using a specific image. The image has been configured\nwith settings and applications that will be used by engineering to develop a new product by the\ncompany.\nThe image is not available on the desired cluster, but it is available in other cluster associated with Prism\nCentral.\nWhy isno’t the image available?"}],"options":["The image bandwidth policy has prevented the image upload.","The cluster should be removed from all categories.","The cluster has not been added to the correct category","The image placement policy was configured with enforcement."],"goodAnswer":[3],"explanations":[{"txt":"La réponse à cette question est D. La politique de placement d'image a été configurée avec l'application de la règle.\n\nDans le scénario décrit, l'image VM nécessaire pour le déploiement n'est pas disponible sur le cluster souhaité, mais elle est disponible sur un autre cluster associé à Prism Central. Cela peut être dû à une configuration de politique de placement d'image qui force l'image à rester sur un cluster spécifique, plutôt que de permettre sa distribution sur plusieurs clusters.\n\nLes autres options ne correspondent pas aux raisons potentielles pour lesquelles l'image n'est pas disponible sur le cluster souhaité :\n\nA. La politique de bande passante de l'image empêche le téléchargement de l'image. Cela concerne la vitesse de transfert de l'image, mais cela ne semble pas être la raison pour laquelle l'image n'est pas disponible sur le cluster.\n\nB. Le cluster devrait être retiré de toutes les catégories. Cela ne semble pas être une action appropriée pour rendre l'image disponible sur le cluster souhaité.\n\nC. Le cluster n'a pas été ajouté à la bonne catégorie. Bien que la catégorisation des clusters puisse affecter la disponibilité de certaines ressources, il est peu probable que ce soit la seule raison pour laquelle l'image n'est pas disponible sur le cluster souhaité."}],"id":10},{"question":[{"txt":"After running an LCM inventory it is noticed that there are a number of firmware and software updates\navailable. The administrator would like to avoid any host reboots, but would like to apply some of the\navailable updates?"}],"options":["M.2 Drives","AHV","Data Drives","AOS"],"goodAnswer":[1,3],"explanations":[{"txt":"AHV is the Acropolis Hypervisor that is used to run Nutanix clusters, and firmware and software updates\ncan be applied to it without requiring any host reboots. AOS is the Acropolis Operating System that\nincludes the hypervisor, storage and management components of the Nutanix cluster, and firmware and\nsoftware updates can also be applied to it without requiring any host reboots.\n"}],"id":11},{"question":[{"txt":"An administrator is troubleshooting vDisk performance issues in a Nutanix cluster with hybrid disks. The VMs all have Flash Mode enabled.\nBut users are reporting disk latency.\nWhat could cause the performance issues?"}],"options":["Flash mode is disabled when a node fails.","Compression is disabled on the vDisk storage container.","The VMs vDisks are in multiple containers.","Data size for flash mode exceeds 25% of the SSD capacity."],"goodAnswer":[3],"explanations":[{"txt":"La réponse à cette question est D. La taille des données pour le mode Flash dépasse 25% de la capacité des SSD.\n\nLorsque le mode Flash est activé sur une machine virtuelle (VM) dans un cluster Nutanix avec des disques hybrides (une combinaison de disques SSD et HDD), il est recommandé de surveiller la quantité de données qui sont activement accédées et qui doivent être stockées dans la couche flash (SSD). Nutanix recommande généralement que la taille des données actives stockées en mode Flash ne dépasse pas 25% de la capacité des SSD disponibles.\n\nSi la taille des données actives dépasse cette limite de 25%, cela peut entraîner des problèmes de performance, tels que des latences de disque plus élevées, car les données doivent être déplacées entre les couches de stockage (flash et disque dur) plus fréquemment, ce qui peut ralentir les opérations d'E/S.\n\nLes autres options ne semblent pas directement liées aux problèmes de performance des disques vDisk dans ce contexte :\n\nA. Le mode Flash est désactivé lorsqu'un nœud échoue : Cela peut causer une perte de performances, mais cela ne semble pas être la cause principale des problèmes de latence de disque signalés par les utilisateurs.\nB. La compression est désactivée sur le conteneur de stockage vDisk : Bien que la compression puisse affecter les performances de stockage, cela ne semble pas être la cause principale des problèmes de latence de disque signalés par les utilisateurs.\nC. Les vDisks des VM sont dans plusieurs conteneurs : Bien que cela puisse être une considération de conception, cela ne semble pas être la cause principale des problèmes de latence de disque signalés par les utilisateurs.\n\n\n\n\n\n\n\n"}],"id":12},{"question":[{"txt":"An administrator is performing validation testing of a new-deploy cluster. During this test, the\nadministrator disconnect each LAN interface from each of the nodes while pinging the hypervisor and\nguest VMs.\nWhen the first interface is disconnected, pings continue as expected to the hypervisor, but pings stop\nresponding from the guest. Pings continue when the interface is reconnected. When the second\ninterface is disconnected, pings continue to both the hypervisor and guest VMs.\nWhat could be the cause of this error?"}],"options":["This is normal behavior for a LAN Failover","Switch ports are configured with different VLANs","Portfast is not enabled on the switch ports","One of the network interfaces has a bad patch cable."],"goodAnswer":[1],"explanations":[{"txt":"La réponse à cette question est B. Les ports du commutateur sont configurés avec des VLAN différents.\n\nLorsque le premier interface LAN est déconnecté et que les pings continuent à répondre au hyperviseur mais pas aux machines virtuelles invitées, cela suggère que les interfaces des machines virtuelles et du hyperviseur sont sur des VLAN différents. Cela peut être dû à une mauvaise configuration des ports du commutateur, où les interfaces sont attribuées à des VLAN différents.\n\nLorsque le deuxième interface est déconnecté et que les pings continuent à répondre, cela confirme que le problème réside dans la configuration des VLAN sur les ports du commutateur, car la déconnexion du deuxième interface n'affecte pas la connectivité. Cela indique que le trafic pour les deux types d'interfaces (hyperviseur et machines virtuelles) est maintenant acheminé correctement.\n\nLes autres options ne correspondent pas aux comportements observés :\n\nA. Ce comportement ne correspond pas à une bascule LAN (LAN Failover), car dans ce cas, la connectivité à la fois avec le hyperviseur et les machines virtuelles serait perdue lorsque le premier interface est déconnecté.\n\nC. L'absence d'activation de Portfast sur les ports du commutateur peut causer des problèmes de connectivité, mais cela n'expliquerait pas pourquoi la connectivité est perdue uniquement avec les machines virtuelles lors de la déconnexion du premier interface, puis rétablie lorsque le premier interface est reconnecté.\n\nD. Un câble réseau défectueux sur une interface ne provoquerait pas une perte de connectivité uniquement avec les machines virtuelles lorsque le premier interface est déconnecté, tout en maintenant la connectivité avec le hyperviseur."}],"id":13},{"question":[{"txt":"What is the minimum time a newly created Deduplication storage policy takes to apply to the VMs in\nthe container?"}],"options":["5 Minutes","10 minutes","30 minutes","60 minutes"],"goodAnswer":[2],"explanations":[{"txt":"https://portal.nutanix.com/page/documents/details?targetId=Prism-Central-Guide-vpc_2023_4:mul-cluster-storage-policy-pc-c.html\n\nThe storage policy engine takes 30 minutes or more to apply a newly created storage policy to the associated entities like VMs. The time taken depends on the number of entities associated with the storage policy."}],"id":14},{"question":[{"txt":"Refer to the exhibit."},{"img":"1710779056343.png"},{"txt":"An administrator is adding a new node to a cluster. The node has been imaged to the same versions of\nAHV and AOS that the cluster running, configured with appropriate IP addresses, and br0-up has been configured the same the existing uplink bonds When attempting to add the node to the cluster with the Expand Cluster function in Prism , the cluster is unable to find the new node.\nBased on the above output from the new node, what is most likely the cause of this issue?\n"}],"options":["The ports on the upstream switch are not configured for LACP.","The existing and the expansion node are on different VLANs.","There is a firewall blocking the discovery traffic from the tlu","LACP configuration must be completed after cluster expansion"],"goodAnswer":[1],"explanations":[{"txt":"B. Les nœuds existants et d'expansion sont sur des VLAN différents.\n\nLe message d'erreur indique que le cluster ne peut pas trouver le nouveau nœud lors de l'expansion. Si les nœuds existants et le nouveau nœud sont sur des VLAN différents, cela peut empêcher la communication et la découverte entre eux, ce qui expliquerait pourquoi le cluster ne peut pas détecter le nouveau nœud.\n\nLes autres options ne semblent pas aussi probables :\n\nA. Si les ports sur le commutateur amont ne sont pas configurés pour LACP (Link Aggregation Control Protocol), cela peut causer des problèmes de connectivité, on voit bien qu'ils sont configurés correctement\n\nC. A moins qu'un pare-feu très restrictif soit délibérément configuré pour bloquer spécifiquement le trafic entre les nœuds du cluster, il est peu probable qu'un pare-feu soit la cause du problème.\n\nD. La configuration LACP est généralement nécessaire pour le regroupement de liens après l'expansion du cluster, mais cela ne devrait pas empêcher le cluster de détecter le nouveau nœud lors de l'expansion."}],"id":15},{"question":[{"txt":"Refer to the exhibit."},{"img":"1710841529391.png"},{"txt":"An administrator is trying to implement the solution that is shown in the exhibit, but has been\nunsuccessful.\nBased on the diagram, what is causing the issue?"}],"options":["A remote Witness VM","Active containers in both sites","Network latency","Unsupported hypervisor"],"goodAnswer":[2],"explanations":[{"txt":"C. Latence réseau.\n\nDans le schéma, on observe que la latence réseau entre les deux sites est de 25 ms (Round Trip Time - RTT). Cette latence peut être considérée comme relativement élevée pour une configuration de haute disponibilité (HA) où les données doivent être synchronisées en temps réel entre les deux sites. Une latence réseau élevée peut entraîner des retards dans la réplication des données et des problèmes de synchronisation entre les clusters.\n\nAinsi, la latence réseau élevée entre les sites A et B pourrait être la cause des problèmes rencontrés par l'administrateur lors de la mise en œuvre de la solution. Cela pourrait affecter la réplication des données et la cohérence entre les clusters, entraînant ainsi des échecs ou des problèmes de disponibilité.\n\nLes autres options ne semblent pas être des causes directes des problèmes"}],"id":16},{"question":[{"txt":"The administrator recently had a node fail in an AHV Nutanix cluster. All of the VMs restarted on other\nnodes in the cluster, but they discovered that the VMs that make up a SQL cluster were running on the\nfailed host. The administrator has been asked to take measures to prevent a SQL outage in the future.\nWhat affinity option will prevent the SQL VMs from running on the same host ?\n"}],"options":["VM-VM anti-Affinity policy","Create Affinity Category","VM-Most Affinity policy","Create Affinity Project"],"goodAnswer":[0],"explanations":[{"txt":"La réponse à cette question est A. Politique d'anti-affinité VM-VM.\n\nEn configurant une politique d'anti-affinité VM-VM pour les VMs qui composent le cluster SQL, l'administrateur peut spécifier que ces machines virtuelles ne doivent pas être exécutées sur le même nœud physique. Cela garantit une meilleure tolérance aux pannes en répartissant les charges de travail critiques sur différents nœuds du cluster Nutanix AHV, réduisant ainsi le risque d'interruption du service en cas de panne d'un nœud.\n\nhttps://portal.nutanix.com/page/documents/details?targetId=AHV-Admin-Guide-v6_1:ahv-affinity-policies-c.html"}],"id":17},{"question":[{"txt":"After logging into Prism Element, an administrator presses the letter A on the Keyboard.\nWhat is the expected outcome of this input?"}],"options":["Alerts page will launch","Analysis will launch","About Nutanix page will launch","API Explorer page will launch"],"goodAnswer":[0],"explanations":[{"txt":"A. La page des alertes se lancera.\n\nEn appuyant sur la touche A dans Prism Element, l'administrateur peut accéder rapidement à la page des alertes, où il peut consulter et gérer les alertes générées par le cluster Nutanix.\n\nKeyboard Shortcuts in Prism Web Console :\nhttps://portal.nutanix.com/page/documents/details?targetId=Web-Console-Guide-Prism-v6_7:wc-shortcut-keys-wc-r.html"}],"id":18},{"question":[{"txt":"An administrator needs to increase bandwidth available to the AHV host and to the CVM.\nHow should the administrator complete this task?"}],"options":["In Prism, update vs0 to change the configuration to Active-Active.","Use manage-ovs commands to update br0 change the configuration to Active-Active.","In Prism, create a vsl interface and add any remaining uplinks.","Use manage-ovs commands to create br1 and add any remaining uplinks"],"goodAnswer":[1],"explanations":[{"txt":"B. Utiliser les commandes manage-ovs pour mettre à jour br0 et changer la configuration en Active-Active.\n\nLa commande manage-ovs est utilisée pour gérer les commutateurs virtuels dans l'environnement AHV de Nutanix. En utilisant manage-ovs, l'administrateur peut mettre à jour le commutateur br0 pour changer la configuration vers Active-Active, ce qui permettra d'augmenter la bande passante disponible pour les hôtes AHV et les machines virtuelles (CVM).\n\nLes autres options ne sont pas correctes car :\n\nA. Mettre à jour vs0 dans Prism pour changer la configuration en Active-Active n'est pas la méthode appropriée pour augmenter la bande passante pour les hôtes AHV et les CVM.\n\nC. Créer une interface vsl dans Prism et ajouter les liens restants n'est pas la méthode appropriée pour augmenter la bande passante pour les hôtes AHV et les CVM.\n\nD. Créer br1 à l'aide de commandes manage-ovs ne correspond pas à l'approche standard pour augmenter la bande passante pour les hôtes AHV et les CVM."}],"id":19},{"question":[{"txt":"Which inefficient VM Profile can be used to identify a VM that consumes too many resources and causes\nother VMs to starve?"}],"options":["Over-provisioned VM"," Inactive VM","Bully VM","Constrained VM"],"goodAnswer":[2],"explanations":[{"txt":"C. Bully VM.\n\nUn \"Bully VM\" (VM agressif) est une VM qui consomme de manière excessive les ressources d'un cluster, ce qui peut entraîner une pénurie de ressources pour d'autres VMs dans le même cluster. Cette VM agressive peut monopoliser les ressources, entraînant une performance médiocre ou une indisponibilité pour les autres VMs.\n\nLes autres options ne sont pas correctes car :\n\nA. Une VM surdimensionnée (Over-provisioned VM) est une VM qui dispose de plus de ressources qu'elle n'en a besoin. Bien qu'elle puisse ne pas utiliser efficacement les ressources, elle n'est pas nécessairement une cause directe de l'épuisement des ressources pour les autres VMs.\n\nB. Une VM inactive (Inactive VM) est une VM qui n'utilise pas actuellement ses ressources allouées. Bien qu'elle puisse occuper de l'espace dans le cluster, elle ne contribue pas directement à l'épuisement des ressources pour les autres VMs.\n\nD. Une VM contrainte (Constrained VM) est une VM qui est limitée en termes de ressources allouées. Bien qu'elle puisse souffrir d'une performance médiocre, elle n'est pas nécessairement une cause directe de l'épuisement des ressources pour les autres VMs.\n\nBehavioral Learning Tools :\nhttps://portal.nutanix.com/page/documents/details?targetId=Prism-Central-Guide-Prism-vpc_2022_4:mul-behavioral-learning-pc-c.html"}],"id":20},{"question":[{"txt":"What is he recommended approach for a constrained VM?"}],"options":["Reboot the VM","Delete the VM.","Increase the VM resources.","Decrease the VM resources"],"goodAnswer":[2],"explanations":[{"txt":"L'approche recommandée pour une VM contrainte est d'augmenter les ressources allouées à la VM. Cela peut inclure l'ajout de vCPU supplémentaires, de mémoire RAM ou d'autres ressources selon les besoins de la charge de travail de la VM. En augmentant les ressources disponibles pour la VM, on peut améliorer sa performance et résoudre les problèmes de contraintes de ressources.\n\nLes autres options ne sont pas recommandées car :\n\nA. Redémarrer la VM (Reboot the VM) peut temporairement résoudre certains problèmes, mais cela ne résout pas le problème sous-jacent de contrainte de ressources.\n\nB. Supprimer la VM (Delete the VM) est une action radicale et n'est pas appropriée pour résoudre les problèmes de contrainte de ressources, sauf si la VM n'est plus nécessaire.\n\nD. Diminuer les ressources de la VM (Decrease the VM resources) aggraverait probablement le problème en réduisant encore plus les ressources disponibles pour la VM, ce qui pourrait entraîner une performance encore plus médiocre."}],"id":21},{"question":[{"txt":"An administrator wants to expand the Failure Domain level of a cluster.\nWhat two options are available? (Choose two.)\n"}],"options":["Node","Data Center","Block","Rack"],"goodAnswer":[2,3],"explanations":[{"txt":"Les deux options disponibles pour étendre le niveau de domaine de défaillance (Failure Domain) d'un cluster sont :\n\nC. Block (Bloc)\nD. Rack (Baie)\n\nCes options permettent d'augmenter la résilience du cluster en définissant des niveaux supplémentaires de domaine de défaillance, ce qui signifie que les machines virtuelles et les données sont distribuées sur un ensemble plus large de ressources physiques. Cela améliore la tolérance aux pannes en réduisant les risques associés à la défaillance de composants matériels spécifiques.\n"}],"id":22},{"question":[{"txt":"What is a requirement to enable Flow Neworking?\n"}],"options":["A dedicated virtual switch has been created for Flow Networking.","Flow Micro segmentation must be enabled.","Microservices infrastructure must be enabled.","Prims Central is using a three-node scale-out deployment"],"goodAnswer":[2],"explanations":[{"txt":"Prerequisites for Flow Virtual Networking :\n\nhttps://portal.nutanix.com/page/documents/details?targetId=Nutanix-Flow-Virtual-Networking-Guide-vpc_2023_4:ear-flow-nw-requirements-pc-r.html"}],"id":23},{"question":[{"txt":"A user running a Computer Aided Design (CAD) application is complaining about slow response time\nwithin the VM, particular when moving windows or rendering images.\nWhich VM metric will guide the administrator toward diagnosing the problem?\n"}],"options":["Storage Controller Latency","GPU Usage","Swap in Rate","Hypervisor Memory Usage (%)"],"goodAnswer":[1],"explanations":[{"txt":"B. Utilisation du GPU (GPU Usage).\n\nDans le cas d'une application de conception assistée par ordinateur (CAO) qui rencontre des problèmes de réponse lente, en particulier lors du déplacement de fenêtres ou du rendu d'images, l'utilisation du GPU est un indicateur crucial. Les applications de CAO sont souvent gourmandes en ressources graphiques et dépendent fortement des performances du processeur graphique pour des opérations telles que le rendu d'images et le déplacement de fenêtres. Par conséquent, si l'utilisation du GPU est élevée, cela pourrait indiquer que le GPU est saturé et peut être une cause de la lenteur de la réponse de l'application.\n\nLes autres options ne sont pas aussi pertinentes dans ce contexte :\n\nA. Latence du contrôleur de stockage (Storage Controller Latency) : Cette métrique se concentre sur les performances de stockage, ce qui peut être important dans certains scénarios, mais n'est pas directement liée aux performances de rendu graphique dans une application de CAO.\n\nC. Taux de swap-in (Swap in Rate) : Cette métrique indique la vitesse à laquelle les pages de mémoire sont lues depuis le stockage de swap vers la mémoire principale, ce qui est généralement lié à la gestion de la mémoire virtuelle et n'est pas spécifique aux problèmes de performance graphique.\n\nD. Utilisation de la mémoire par l'hyperviseur (Hypervisor Memory Usage (%)) : Cette métrique concerne l'utilisation de la mémoire par l'hyperviseur, ce qui peut être important pour la surveillance et la gestion des ressources, mais n'est pas directement liée aux performances graphiques de l'application de CAO."}],"id":24},{"question":[{"txt":"An administrator needs to ensure logs, alerts and information is consistent across clusters that are\nlocated in different countries.\nWhich service needs to be configured?\n"}],"options":["SMTP","DNS","SNMP","NTP"],"goodAnswer":[3],"explanations":[{"txt":"D. NTP (Network Time Protocol).\n\nPour garantir que les journaux, alertes et informations sont cohérents à travers les clusters situés dans différents pays, il est essentiel de synchroniser l'horloge de tous les appareils et serveurs dans ces clusters. Cela garantit que les événements sont horodatés de manière cohérente, facilitant ainsi la corrélation des informations entre les différents clusters.\n\nLe service utilisé pour synchroniser l'horloge des appareils est le protocole NTP (Network Time Protocol). En configurant des serveurs NTP correctement, les clusters peuvent maintenir des horloges précises et cohérentes, contribuant ainsi à une gestion des journaux, des alertes et des informations plus efficace et fiable à travers les frontières nationales.\n\nLes autres options ne sont pas directement liées à la synchronisation de l'horloge et à la cohérence des journaux, alertes et informations entre les clusters :\n\nA. SMTP (Simple Mail Transfer Protocol) est utilisé pour la transmission des e-mails. Bien qu'important pour la notification des alertes, il ne garantit pas la cohérence des informations entre les clusters.\n\nB. DNS (Domain Name System) est utilisé pour la résolution des noms de domaine en adresses IP et vice versa, mais il n'a pas de lien direct avec la cohérence des journaux et des alertes entre les clusters.\n\nC. SNMP (Simple Network Management Protocol) est utilisé pour la surveillance et la gestion des équipements réseau, mais il n'est pas directement lié à la cohérence des journaux et des alertes entre les clusters.\n\n\n\n\n\n\n"}],"id":25},{"question":[{"txt":"An administrator manages an AHV cluster that is dedicated to a dev/test environment. The administrator\nreceiving complaints from users that they are unable to create new VMs on the cluster.\nAfter the reviewing the cluster, the administrator finds that the memory resources are almost fully\nutilized, with many VMs over-provisioned on memory.\nWhat option is the most efficient resolution to enable additional VMs to be created?\n"}],"options":["Enable Memory Overcommit on the over-provisioned VMs.","Enable Memory HA on the over-provisioned VMs.","Upgrade the nodes with additional memory DlMMs.","Disable HA Reservation on the cluster."],"goodAnswer":[3],"explanations":[{"txt":"D. Désactiver la réservation HA sur le cluster.\n\nEn désactivant la réservation HA, cela libérerait de la mémoire qui est actuellement réservée pour les besoins de haute disponibilité. Cela pourrait permettre la création de nouvelles machines virtuelles en utilisant cette mémoire supplémentaire disponible. Cependant, il est important de noter que cela compromettrait la redondance et la disponibilité des machines virtuelles dans le cluster.\n\nA. Activer la surprovision de mémoire (Memory Overcommit) sur les VMs surprovisionnées : Cette option permettrait aux VMs d'utiliser plus de mémoire que ce qui leur est formellement alloué. Cependant, si les ressources sont déjà presque entièrement utilisées, cela pourrait ne pas suffire pour créer de nouvelles VMs sans risque de performance dégradée pour les VMs existantes.\n\nB. Activer la haute disponibilité de la mémoire (Memory HA) sur les VMs surprovisionnées : La haute disponibilité de la mémoire garantirait la redondance et la reprise après incident pour les VMs, mais cela ne libérerait pas directement de la mémoire pour permettre la création de nouvelles VMs.\n\nC. Mettre à niveau les nœuds avec de la mémoire supplémentaire (DIMMs) : Cette option serait une solution viable si des ressources supplémentaires sont nécessaires et que la capacité de mémoire du cluster est le goulot d'étranglement. Cependant, cela peut être une solution coûteuse et prendre du temps à implémenter."}],"id":26},{"question":[{"txt":"Refer to Exhibit"},{"img":"1710854853283.png"},{"txt":"The Update Source for LCM has been configured as shown in the exhibit. Inventory is failing consistently.\nWhat is the likely cause of this issue?\n"}],"options":["Port 433 Is blocked by a firewall.","Port 80 is blocked by a firewall.","The administrator does not have a valid portal account.","The license assigned to the cluster has expired."],"goodAnswer":[0],"explanations":[{"txt":"A. Le port 443 est bloqué par un pare-feu.\n\nLe fait que la configuration indique \"Enable HTTPS\" et \"Allow LCM to access Nutanix Portal Over HTTPS\" suggère que la communication devrait se faire via HTTPS, ce qui utilise généralement le port 443. Si ce port est bloqué par un pare-feu, cela empêcherait effectivement LCM de se connecter au portail Nutanix pour récupérer les mises à jour et les informations d'inventaire nécessaires, ce qui entraînerait des échecs d'inventaire.\n\nIl est important de vérifier les paramètres de pare-feu pour s'assurer que le trafic sortant vers le port 443 est autorisé pour permettre à LCM d'accéder au portail Nutanix et de récupérer les mises à jour et les informations d'inventaire."}],"id":27},{"question":[{"txt":"During an AHV upgrade, an administrator finds that a critical VM was powered off rather than migration\nto another host.\nWhich scenario explains this behavior?"}],"options":["NO AHV hosts were able to be scheduled.","The VM OS hung during migration.","The VM was on the same host as the acropolis leader."," The VM was marked as an agent VM."],"goodAnswer":[3],"explanations":[{"txt":"la réponse D semble être la plus appropriée, car la VM critique a été marquée comme une \"Agent VM\". Lorsqu'une VM est marquée comme une \"Agent VM\", cela désactive la haute disponibilité (HA) pour cette VM spécifique, ce qui signifie qu'elle ne sera pas migrée vers un autre hôte en cas de panne ou de maintenance, et peut être éteinte si le nœud sur lequel elle se trouve doit être mis hors service.\n\n\nBien sûr, voici des explications pour les autres réponses :\n\nA. Aucun hôte AHV n'a pu être planifié : Cette réponse est peu probable car si aucun hôte AHV n'était disponible pour la migration, il serait plus probable que la VM soit mise hors tension ou arrêtée en raison de l'indisponibilité des ressources, plutôt que d'être migrée sur un autre hôte. Dans ce cas, l'absence de planification d'hôtes AHV ne justifierait pas nécessairement l'arrêt de la VM.\n\nB. Le système d'exploitation de la VM s'est figé pendant la migration : Bien que cela puisse arriver, cela n'expliquerait pas nécessairement pourquoi la VM a été arrêtée plutôt que migrée. Si le système d'exploitation de la VM s'était figé pendant la migration, la VM aurait pu rester en cours de migration ou être annulée, mais pas nécessairement mise hors tension.\n\nC. La VM était sur le même hôte que le leader d'Acropolis : Cette réponse semble également peu probable car, dans la plupart des cas, la VM ne serait pas mise hors tension simplement parce qu'elle est sur le même hôte que le leader d'Acropolis. Cependant, si le leader d'Acropolis devait être migré pendant la mise à niveau AHV et que la VM critique était sur le même hôte, cela pourrait expliquer pourquoi elle a été arrêtée plutôt que migrée vers un autre hôte. Cependant, la réponse D semble être la meilleure réponse car elle est plus spécifique au comportement attendu des \"Agent VM\"."}],"id":28},{"question":[{"txt":"Which two types of granular RBAC does Nutanix provide for AHV hosts? (Choose two.)"}],"options":["Category based","Project based","Disk based","Cluster based"],"goodAnswer":[0,1],"explanations":[{"txt":"Les deux types de contrôle d'accès basés sur les rôles (RBAC) offerts par Nutanix pour les hôtes AHV sont :\n\nA. Basé sur les catégories (Category based) : Ce type de RBAC permet de définir des autorisations basées sur les catégories attribuées aux objets, tels que les VMs, les conteneurs de stockage, etc. Les utilisateurs peuvent être autorisés à effectuer des actions spécifiques sur les objets associés à une catégorie particulière.\n\nB. Basé sur les projets (Project based) : Ce type de RBAC permet de définir des autorisations spécifiques pour les projets, qui regroupent généralement un ensemble d'objets liés à un projet spécifique. Les autorisations peuvent être attribuées aux utilisateurs en fonction de leur rôle dans le projet, leur permettant d'accéder et de gérer les ressources associées à ce projet.\n\nLes autres options, telles que le contrôle d'accès basé sur les disques (Disk based) ou basé sur les clusters (Cluster based), ne sont pas des types de RBAC couramment associés à Nutanix AHV."}],"id":29},{"question":[{"txt":"An administrator is tasked with configuring networking on an AHV cluster and needs to optimize for\nmaximum single VM throughput.\nWhich bond mode should the administrator select?"}],"options":["Active-Active with Mac pinning","Active-Active","Active-Backup","No Uplink Bond"],"goodAnswer":[1],"explanations":[{"txt":"B. Active-Active\n\nDans un environnement où l'objectif est d'optimiser le débit maximal d'une seule machine virtuelle, le mode de liaison Active-Active est généralement préférable. Dans ce mode, toutes les interfaces réseau agrégées dans le bond sont actives simultanément, ce qui permet une répartition équilibrée du trafic sur toutes les interfaces. Cela permet à une seule machine virtuelle de bénéficier de la capacité combinée de toutes les interfaces, augmentant ainsi le potentiel de débit maximal.\n\nLes autres options ne sont pas aussi adaptées dans ce contexte :\n\nA. Active-Active avec Mac pinning : Bien que ce mode soit également Active-Active, l'ajout de Mac pinning limite le trafic de chaque VM à une seule interface physique. Cela peut être utile dans certains cas, mais cela ne garantit pas nécessairement le débit maximal pour une seule VM.\n\nC. Active-Backup : Dans ce mode, une seule interface est active à la fois, tandis que les autres restent en mode de sauvegarde. Cela ne maximiserait pas le débit pour une seule VM car seule une interface est active à la fois.\n\nD. No Uplink Bond : Sans liaison montante (bond), le débit serait limité à la capacité d'une seule interface réseau, ce qui ne permettrait pas d'atteindre le débit maximal pour une seule VM.\n\nLoad Balancing in Bond Interfaces:\nhttps://portal.nutanix.com/page/documents/solutions/details?targetId=BP-2071-AHV-Networking:load-balancing-in-bond-interfaces.html"}],"id":30},{"question":[{"txt":"An administrator wants to replace and old node with a node of newer generation in a 3-node cluster. The\nadministrator has already chosen the appropriate node. But unable to remove it from the cluster.\nWhy is the Remove Host option not shown in the exhibit?\n"}],"options":["The host needs to be placed into maintenance Mode before.","It is only possible to remove a host from a cluster using CLI.","It is not possible to remove a node from a the cluster using Prism Central","It is not possible to remove a host from a 3-node cluster."],"goodAnswer":[2],"explanations":[{"txt":"Removing a Node through Prism Central:\nhttps://portal.nutanix.com/page/documents/details?targetId=Prism-Central-Guide-vpc_2023_4:mul-node-remove-pc.t.html\n\nLimitations for Removing a Node through Prism Central\nConsider the following limitations before you remove a node from a cluster.\n\nFor an RF1 or RF2 enabled cluster, the minimum number of nodes to support node removal is four. You cannot remove a node from a cluster that has less than four nodes.\nFor an RF3 enabled cluster, the minimum number of nodes to support node removal is five. You cannot remove a node from an RF3-enabled cluster that has less than five nodes.\nYou can remove only one node at a time."}],"id":31},{"question":[{"txt":"An administrator needs to create a new Linux image and will to do the following as part of the VM\ndeployment:\n* Set the OS hostname\n* Add custom users\n* Add keys\n* Run custom scripts\nWhat package needs to be installed in the Linux image to facilitate this automation?\n"}],"options":["CloudInit","Sysprep"],"goodAnswer":[0],"explanations":[{"txt":"A. CloudInit\n\nCloudInit est un package largement utilisé dans les environnements cloud pour automatiser la configuration initiale des instances de machines virtuelles Linux. Il permet d'effectuer des tâches telles que la configuration du nom d'hôte du système d'exploitation, l'ajout d'utilisateurs personnalisés, l'ajout de clés SSH et l'exécution de scripts personnalisés lors du déploiement de la VM.\n\nSysprep, en revanche, est principalement utilisé dans les environnements Windows pour préparer une image système pour le déploiement sur plusieurs machines. Il est utilisé pour généraliser une image Windows en supprimant les informations spécifiques à une machine, telles que le SID (Security Identifier), afin de garantir que chaque machine déployée à partir de l'image dispose d'une identité unique."}],"id":32},{"question":[{"txt":"An administrator has created a Nutanix managed it a VLAN ID of 512.\nSeveral VMs have been created, and the administrator notices that the can successfully communicate\nwith other VMs on that VLAN.\nProvided they are on the host, but cannot communicate with VMs that reside on different hosts in the\ncluster.\nWhat is most likely thee cause of this issue?\n"}],"options":["There is a firewall rule blockingVLAN512 traffic.","VLAN512 is a reserved VLAN ID, and not usable for guest VMs.","The VLAN was not created on the upstream switches."],"goodAnswer":[2],"explanations":[{"txt":"C. Le VLAN n'a pas été créé sur les commutateurs amont.\n\nLorsque des machines virtuelles sont déployées sur différents hôtes d'un cluster, elles doivent pouvoir communiquer entre elles via le réseau. Pour ce faire, le VLAN auquel elles sont connectées doit être configuré sur les commutateurs réseau amont pour permettre le routage du trafic entre les hôtes. Si le VLAN n'a pas été créé correctement sur les commutateurs réseau amont, les machines virtuelles sur des hôtes différents ne pourront pas communiquer entre elles, même si elles sont dans le même VLAN.\n\nLes autres options sont moins probables :\n\nA. Il y a une règle de pare-feu bloquant le trafic VLAN512 : Cela pourrait être une possibilité, mais elle est moins probable que l'absence de configuration VLAN sur les commutateurs amont, car les règles de pare-feu sont généralement configurées pour des politiques spécifiques et ne seraient pas spécifiquement liées à un seul VLAN sans raison apparente.\n\nB. VLAN512 est un ID de VLAN réservé et n'est pas utilisable pour les VM invitées : Cette réponse est moins probable car le fait que les VMs sur le même hôte puissent communiquer avec succès indique que le VLAN est utilisable pour les VMs invitées. Si VLAN512 était réservé, aucune communication ne serait possible."}],"id":33},{"question":[{"txt":"An administrator is concerned about the amount of data that a VM reading and writing to the storage\nfabric.\nWhich metric will provide that data?"}],"options":["Host Hypervisor IO Bandwidth","Host Disk IOPS","VM Storage Controller IOPS","VM Storage Controller Bandwidth"],"goodAnswer":[2],"explanations":[{"txt":"C. VM Storage Controller IOPS\n\nLes IOPS (Input/Output Operations Per Second) mesurent le nombre d'opérations d'entrée/sortie (lectures et écritures) que la machine virtuelle effectue sur le stockage. Le comptage des IOPS au niveau du contrôleur de stockage de la VM fournira des informations sur la quantité de données que la VM lit et écrit sur le stockage. Cela permet à l'administrateur de surveiller de près l'activité de stockage de la VM et d'identifier toute charge de travail intense en termes d'entrées/sorties."}],"id":34},{"question":[{"txt":"An administrator receives complaints of poor performance in a particular VM.\nBased on the VM performance metric, what is the most likely cause of this behavior?"}],"options":["Oplog is full cannot serve IO request from this VM.","The host’s CPU is severely overloaded.","SSD tier is not big enough to serve workloads’ IOPS demand.","The VM needs more vCPUs"],"goodAnswer":[3],"explanations":[{"txt":"D. The VM needs more vCPUs\n\nSi un utilisateur signale une mauvaise performance pour une machine virtuelle spécifique, cela peut être dû à une allocation insuffisante de ressources, telles que le CPU. Si la machine virtuelle ne dispose pas de suffisamment de vCPUs pour traiter ses charges de travail, elle peut rencontrer des goulets d'étranglement de performance, entraînant une mauvaise réactivité et des temps de réponse lents.\n\nLes autres réponses sont moins susceptibles d'être la cause du problème :\n\nA. L'oplog est plein et ne peut pas répondre aux demandes d'I/O de cette VM : Cela pourrait entraîner des problèmes de performance, mais cela ne serait pas lié spécifiquement à la nécessité de plus de vCPUs pour la VM.\n\nB. Le CPU de l'hôte est gravement surchargé : Cela pourrait affecter les performances globales du système, mais cela ne serait pas spécifiquement lié à une seule VM, à moins que toutes les VMs sur l'hôte ne subissent des problèmes de performance.\n\nC. Le SSD tier n'est pas assez grand pour répondre à la demande d'IOPS des charges de travail : Cela pourrait affecter les performances globales du stockage, mais cela ne serait pas spécifiquement lié à une seule VM, à moins que toutes les VMs partageant le même stockage ne subissent des problèmes de performance.\n\n\n"}],"id":35},{"question":[{"txt":"Refer to the exhibit."},{"img":"1711113215087.png"},{"txt":"Which two initial cluster configuration tasks were missed during the deployment process? (Choose two.)"}],"options":["Host password changes","Password policy changes","BIOS password changes","CVM password changes"],"goodAnswer":[0,3],"explanations":[{"txt":"Les deux tâches de configuration initiale du cluster qui ont été manquées lors du processus de déploiement sont :\n\nA. Changements de mot de passe hôte (Host password changes) : Il est recommandé de changer les mots de passe par défaut des hôtes pour des raisons de sécurité. Cela garantit que les mots de passe sont sécurisés et ne sont pas laissés à leurs valeurs par défaut, ce qui pourrait rendre le cluster vulnérable aux attaques.\n\nD. Changements de mot de passe CVM (CVM password changes) : Les mots de passe par défaut des machines virtuelles du contrôleur CVM (Controller VM) doivent également être modifiés pour des raisons de sécurité. Modifier les mots de passe par défaut garantit que l'accès à ces machines virtuelles est sécurisé et réduit les risques potentiels de compromission du cluster."}],"id":36},{"question":[{"txt":"An administrator needs to configure a new subnet on an AHV cluster and want to ensure that VMs will\nautomatically be assigned an IP address at creation time.\nWhich type of network does the administrator need to create?"}],"options":["Dynamic Network","Unmanaged Network","Managed Network","DHCP Network"],"goodAnswer":[2],"explanations":[{"txt":"C. Managed Network\n\nEn créant un réseau géré (Managed Network), les machines virtuelles (VMs) pourront automatiquement se voir attribuer une adresse IP au moment de leur création. Dans un réseau géré, Nutanix AHV prend en charge la configuration dynamique des adresses IP via son propre service d'attribution d'adresses IP, éliminant ainsi la nécessité de configurer manuellement les adresses IP pour chaque VM.\n\nLes autres options ne correspondent pas aux exigences spécifiées :\n\nA. Dynamic Network : Ce terme est ambigu et pourrait signifier un réseau géré ou un réseau dynamique qui ne fournit pas nécessairement d'adresses IP automatiquement aux VMs.\n\nB. Unmanaged Network : Dans un réseau non géré, l'administrateur doit configurer manuellement les adresses IP pour chaque VM, ce qui ne répond pas à la demande d'attribution automatique des adresses IP.\n\nD. DHCP Network : Alors que le DHCP (Dynamic Host Configuration Protocol) peut fournir des adresses IP automatiquement, dans le contexte de Nutanix AHV, le réseau géré est utilisé pour fournir cette fonctionnalité, plutôt que d'utiliser un serveur DHCP externe."}],"id":37},{"question":[{"txt":"An administrator was reviewing various AOS logs when a it was noticed that the time of the logs were off by several hours.\nWhich initial step was missed during the post process cluster configuration?"}],"options":["Setting the cluster time zone via PC GUI","Setting the cluster time zone via CVM NCLI","Setting the cluster time zone via PE GUI","Setting the cluster time zone via CVM ACLI"],"goodAnswer":[1],"explanations":[{"txt":"B. Setting the cluster time zone via CVM NCLI\n\nLa réponse B implique que l'étape initiale manquée était de définir le fuseau horaire du cluster via l'interface de ligne de commande (NCLI) sur les machines virtuelles du contrôleur (CVM).\n\nLorsque le fuseau horaire n'est pas correctement configuré sur le cluster via la ligne de commande sur les CVM, cela peut entraîner un décalage d'heure dans les logs et les métriques générés par le cluster. Si les logs sont décalés de plusieurs heures par rapport à l'heure réelle, cela peut rendre le dépannage et l'analyse des problèmes de performance ou de sécurité plus difficiles.\n\nLa configuration du fuseau horaire via la ligne de commande (NCLI) est une étape essentielle pour garantir que tous les composants du cluster, y compris les CVM, sont synchronisés avec le même fuseau horaire. Cela permet d'assurer la cohérence des horodatages dans les logs et les métriques générés par le cluster, facilitant ainsi le dépannage et l'analyse.\n\nhttps://portal.nutanix.com/page/documents/kbs/details?targetId=kA0600000008SNvCAM"}],"id":38},{"question":[{"txt":"Which AOS process determine if an I/O from a user will be written to OpLog or to an Extent Store?"}],"options":["Stargate","Curtor","Cassandara","Zeus"],"goodAnswer":[0],"explanations":[{"txt":"A. Stargate\n\nStargate est le composant logiciel de Nutanix qui gère le chemin d'accès des données entrantes et sortantes pour les opérations d'E/S sur le cluster. Lorsqu'un utilisateur effectue une opération d'entrée/sortie (I/O), Stargate détermine si les données seront écrites dans l'OpLog (Opération Log) ou dans l'Extent Store (Stockage d'Étendue), en fonction de divers facteurs tels que la taille de l'I/O, la stratégie de placement de données et la stratégie de mise en cache.\n\nCLUSTER COMPONENTS :\nhttps://www.nutanixbible.com/2f-book-of-basics-cluster-components.html"}],"id":39},{"question":[{"txt":"A recently configured cluster is leveraging NearSync with a recovery schedule of 15 minutes. It is noticed\nthat the cluster is consistently transitioning in an Out of NearSyne.\nWhat action should be taken to potentially address this issue?"}],"options":["Increase network bandwidth","Change the NearSync schedule to 30 minutes.","Add a vCPUs to the user VMs.","Configure a secondary schedule in the same Protection Domain."],"goodAnswer":[0],"explanations":[{"txt":"A. Augmenter la bande passante réseau\n\nSi le cluster est constamment en dehors de la synchronisation proche (Out of NearSync), cela peut indiquer des problèmes de performance au niveau du réseau, où les données ne peuvent pas être synchronisées à temps en raison de la limitation de la bande passante. En augmentant la bande passante réseau disponible pour le cluster, vous pouvez aider à résoudre ce problème en permettant une synchronisation plus rapide des données entre les nœuds du cluster. Cela peut aider à maintenir la synchronisation proche et à réduire les transitions en dehors de la synchronisation proche."}],"id":40},{"question":[{"txt":"Which scenario would benefit most from Erasure Coding being enabled on a container?"}],"options":["Long term storage of data which is written once and read infrequently","High performance database where all is relatively hot.","VDI use cases where a single VM is cloned 100’s of times","WEB and API Servers"],"goodAnswer":[0],"explanations":[{"txt":"A. Stockage à long terme de données qui sont écrites une seule fois et lues rarement\n\nL'encodage par élimination (Erasure Coding) est particulièrement avantageux pour les cas d'utilisation où l'accent est mis sur la conservation efficace des données avec une redondance réduite. Dans ce scénario, où les données sont écrites une seule fois et lues rarement, l'encodage par élimination peut offrir une efficacité de stockage accrue par rapport à la réplication traditionnelle, en réduisant le surcoût de stockage associé à la redondance. Cela permet d'économiser de l'espace de stockage et de réduire les coûts, ce qui est particulièrement avantageux pour les données à long terme qui ne nécessitent pas une redondance élevée pour la tolérance aux pannes."}],"id":41},{"question":[{"txt":"An administrator logs into the Nutanix Support Portal and notices there is a new version of the LCM Framework available. In an effort ensure LCM is providing the latest features, the administrator would\nlike to upgrade LCM.\nHow can the LCM Framework be upgraded?"}],"options":["Perform an LCM inventory","Upload the latest LCM Framework as an image in the image Configuration in Prism","Upload the latest LCM Framework bundle via Upgrade Software in Prism","Upgrade AOS"],"goodAnswer":[0],"explanations":[{"txt":"LCM performs two functions: taking inventory of the cluster and performing updates on the cluster. LCM updates are not reversible.\n\nBefore performing an update, LCM runs a set of pre-checks to verify the state of the cluster. If any checks fail, LCM stops the update.\n\nLCM writes all operations to output logs:\n\ngenesis.out\nlcm_ops.out\nlcm_op.trace\nlcm_wget.log\nThe log files record all operations, including successes and failures. If an operation fails, LCM suspends it to wait for mitigation. Contact Nutanix Support for assistance if there is an LCM failure.\n\nThe LCM framework can also update itself when necessary. Although connected to AOS, the framework is not part of the AOS release cycle.\n\nDOC LCM:\nhttps://portal.nutanix.com/page/documents/details?targetId=Life-Cycle-Manager-Guide-v2_7:Life-Cycle-Manager-Guide-v2_7"},{"img":"1711116047174.png"}],"id":42},{"question":[{"txt":"An administrator has been asked to enable block awareness and increase the fault tolerance to FT2 on a\nNutanix AHV cluster with the following configuration:\nFour blocks\nOne node per block\nWill the administrator be able to accomplish these tasks?"}],"options":["Remote Protection Group","Local Protection Group","Snap Clones","Shadow Clones"],"goodAnswer":[3],"explanations":[{"txt":"D. Shadow Clones\n\nLes clones d'ombre (Shadow Clones) sont une fonctionnalité de Nutanix qui fournit une optimisation efficace du cache dans les environnements VDI (Virtual Desktop Infrastructure). Les clones d'ombre permettent de créer rapidement des copies de machines virtuelles à partir de machines virtuelles existantes en partageant efficacement les données entre les clones et en minimisant l'espace de stockage utilisé."}],"id":43},{"question":[{"txt":"Which capability refers to the storage of VM data on the node where the VM is running and ensure that\nthe read I/O does not have to traverse the network?"}],"options":["Intelligent Locally","Data Locality","Intelligent Tiering","Data Tiering"],"goodAnswer":[1],"explanations":[{"txt":"B. Data Locality\n\nLa capacité qui se réfère au stockage des données de la machine virtuelle sur le nœud où la machine virtuelle s'exécute et qui garantit que les opérations d'E/S en lecture n'ont pas à traverser le réseau est appelée \"Data Locality\" (Localisation des données). Cette fonctionnalité permet d'améliorer les performances en réduisant la latence liée au réseau et en augmentant la vitesse d'accès aux données pour les opérations d'E/S en lecture."}],"id":44},{"question":[{"txt":"An administrator has received reports of users being disconnected from remote desktop sessions to a specific VM.\nWhich VM metric is most useful isolating the cause of the issue?\n"}],"options":["Storage Controller Bandwidth","Swap-Out Rate","Hypervisor CPU Ready time (%)","Virtual NIC receive packet dropped"],"goodAnswer":[3],"explanations":[{"txt":"La réponse correcte est :\n\nD. Virtual NIC receive packet dropped\n\nLe métrique le plus utile pour isoler la cause du problème de déconnexion des sessions de bureau à distance des utilisateurs vers une VM spécifique est \"Virtual NIC receive packet dropped\" (Paquets reçus de l'interface réseau virtuelle abandonnés). Cette métrique indique le nombre de paquets réseau qui ont été abandonnés lorsqu'ils étaient reçus par l'interface réseau virtuelle de la machine virtuelle. Si cette valeur est élevée, cela peut indiquer des problèmes de connectivité réseau ou de saturation du réseau, ce qui peut être la cause des déconnexions des utilisateurs. En surveillant cette métrique, l'administrateur peut identifier et résoudre les problèmes de connectivité réseau qui affectent les sessions de bureau à distance."},{"txt":"A. Storage Controller Bandwidth (Bande passante du contrôleur de stockage) : Cette métrique mesure la quantité de données transférées vers et depuis le stockage par le contrôleur de stockage. Bien qu'une saturation de la bande passante du contrôleur de stockage puisse affecter les performances globales du système, elle n'est pas directement liée aux déconnexions des sessions de bureau à distance.\n\nB. Swap-Out Rate (Taux de swap) : Cette métrique mesure la fréquence à laquelle des pages de mémoire sont transférées de la mémoire RAM vers le stockage de swap sur le disque en raison d'une pression sur la mémoire. Bien qu'une utilisation intensive du swap puisse entraîner des ralentissements du système, elle n'est généralement pas la cause directe des déconnexions des sessions de bureau à distance.\n\nC. Hypervisor CPU Ready time (%) (Temps d'attente du processeur prêt (%) du hyperviseur) : Cette métrique mesure le pourcentage de temps pendant lequel les machines virtuelles attendent l'accès au processeur sur le hyperviseur. Bien qu'une utilisation élevée du CPU puisse entraîner des problèmes de performances, elle n'est pas directement liée aux déconnexions des sessions de bureau à distance, sauf si elle entraîne une saturation du CPU et des retards dans le traitement des données réseau.\n\nEn conclusion, bien que toutes ces métriques puissent être utiles pour diagnostiquer les problèmes de performances, la métrique la plus pertinente pour isoler la cause des déconnexions des sessions de bureau à distance est \"Virtual NIC receive packet dropped\" (Paquets reçus de l'interface réseau virtuelle abandonnés), car elle indique directement des problèmes de connectivité réseau au niveau de la machine virtuelle."}],"id":45},{"question":[{"txt":"What does Nutanix recommend when setting up the node networkring?"}],"options":["Include NIC models from different vendors in the same bond","Include at least two physically interfaces in every bond.","Combine NIC models from different vendors in the same bond.","Combine NIC models from different vendors in the same bond."],"goodAnswer":[1],"explanations":[{"txt":"Lors de la configuration de la mise en réseau des nœuds dans un cluster Nutanix, Nutanix recommande d'inclure au moins deux interfaces physiques dans chaque bond. Cela permet de fournir une redondance réseau et une tolérance aux pannes en cas de défaillance d'une interface réseau ou d'un lien. Avoir plusieurs interfaces physiques dans chaque bond permet également d'augmenter la capacité de bande passante et d'améliorer les performances du réseau en répartissant la charge du trafic réseau sur plusieurs liaisons physiques. Cette approche contribue à assurer la fiabilité et la disponibilité du réseau dans un environnement Nutanix."},{"img":"1711117461078.png"}],"id":46},{"question":[{"txt":"An administrator is not able to log into Prism Central by using a new Active Directory user account. After\nLogging with the local user, the administrator verified that Directory Services and Role Mapping setting\nare valid.\nWhat is the most likely cause of this issue?\n"}],"options":["Change password at next logon attribute is set.","User does not belong to the Administrators group.","Active Directory functional level of wrong.","Prism Element authentication is not configured."],"goodAnswer":[1],"explanations":[{"txt":"\nLa réponse correcte est :\n\nB. L'utilisateur n'appartient pas au groupe Administrateurs.\n\nLe problème le plus probable dans ce scénario est que l'utilisateur nouvellement créé n'appartient pas au groupe Administrateurs dans Prism Central. Pour accéder à Prism Central, les utilisateurs doivent être membres du groupe Administrateurs ou d'un groupe ayant des autorisations suffisantes pour se connecter."}],"id":47},{"question":[{"txt":"Administrator is creating a Windows 10 VM that will be used for a virtual desktop template. After creating the VM and booting to the ISO, the administrator is unable to install Windows and receives the following error. \n"},{"img":"1711118345893.png"},{"txt":"What steps does the administrator need to take to install the OS?"}],"options":["Load the Nutanix VirtIO Serial Bus Driver.","Load the VirtIO Network Ethernet Adaper.","Load the Nutanix Virtual Balloon Driver.","Load the Virtual SCSI pass-through controller."],"goodAnswer":[3],"explanations":[{"txt":"D. Charger le contrôleur de bus SCSI pass-through virtuel.\n\nLorsque le message d'erreur \"We couldn't find any drives\" apparaît lors de l'installation de Windows, cela signifie que le système d'exploitation ne peut pas détecter les lecteurs de stockage appropriés. Pour résoudre ce problème, l'administrateur doit charger le contrôleur de bus SCSI pass-through virtuel."},{"img":"1711118814185.png"}],"id":48},{"question":[{"txt":"After configuring modules for a Remote Syslog Server, the settings are as shown. The administrator\nnotices that even though the level parameter is set to EMERGENCY, that all monitor logs are being sent.\nWhat is the likely cause of this issue?"}],"options":["A second rsyslog server is configured to send all monitor logs.","Having the Module Name set to STARGATE sends all monitor logs regardless of the level.","A Log Level of EMERGENCY includes all monitor logs.","The true setting for Include Monitor Logs sends all monitor logs regardless of the level."],"goodAnswer":[2],"explanations":[{"txt":"Dans ce scénario,\n\nles journaux de surveillance sont envoyés même si le paramètre de niveau est défini sur EMERGENCY. Cela est dû au fait que le niveau de journalisation EMERGENCY inclut tous les journaux, y compris les journaux de surveillance. Par conséquent, même si le paramètre de niveau est spécifié comme EMERGENCY, tous les journaux de surveillance seront envoyés au serveur Syslog distant."}],"id":49},{"question":[{"txt":"While installing Windows 2019 on a new VM on an AHV cluster, an administrator notices there aren’t any\ndrives listed for the install.\nWhat might the problem be?"}],"options":["VirtIO drivers have not yet been installed and the disks are IDE disks.","VirtIO drivers have not yet been installed and the disks are SCSI disks.","VirtIO drivers must be installed on AHV for installations of Windows.","VirtIO drivers aren’t supported on this version of Windows 2019."],"goodAnswer":[1],"explanations":[{"txt":"B. Les pilotes VirtIO n'ont pas encore été installés et les disques sont des disques SCSI.\n\nLes pilotes VirtIO doivent être installés pour les disques SCSI afin que Windows puisse détecter correctement les disques pendant l'installation.\n\nRéponses incorrectes : \n\nA. Les pilotes VirtIO n'ont pas encore été installés et les disques sont des disques IDE.\nMême si les pilotes VirtIO ne sont pas installés, les disques IDE devraient être détectés lors de l'installation de Windows. Les pilotes VirtIO sont requis pour les disques SCSI, pas pour les disques IDE.\n\n\nVoici les justifications pour chaque réponse :\n\nA. Les pilotes VirtIO n'ont pas encore été installés et les disques sont des disques IDE.\nCela est incorrect car même si les pilotes VirtIO ne sont pas installés, les disques IDE devraient être détectés lors de l'installation de Windows. Les pilotes VirtIO sont requis pour les disques SCSI, pas pour les disques IDE.\n\nB. Les pilotes VirtIO n'ont pas encore été installés et les disques sont des disques SCSI.\nC'est la réponse correcte. Les pilotes VirtIO doivent être installés pour les disques SCSI afin que Windows puisse détecter correctement les disques pendant l'installation.\n\nC. Les pilotes VirtIO doivent être installés sur AHV pour les installations de Windows.\nCette réponse est trop générale et ne répond pas directement au problème spécifique des disques non détectés pendant l'installation de Windows.\n\nD. Les pilotes VirtIO ne sont pas pris en charge sur cette version de Windows 2019.\nLes pilotes VirtIO sont pris en charge sur Windows 2019 et sont nécessaires pour les disques SCSI sur AHV.\n\n"}],"id":50},{"question":[{"txt":"Which baseline is used to identify a Zombie VM?"}],"options":["VM is powered off for the past 21 days.","Memory usage is less than 1% and memory swap rate is equal to 0 Kbps for the past 21 days.","VM has no logins for the past 21 days","Fewer than 30 1/Os and less than 1000 bytes per day of network traffic for the past 21 days"],"goodAnswer":[3],"explanations":[{"txt":"Doc : \nhttps://portal.nutanix.com/page/documents/details?targetId=Prism-Central-Guide-Prism-vpc_2022_4:mul-behavioral-learning-pc-c.html\n"},{"img":"1711379487084.png"}],"id":51},{"question":[{"txt":"An administrator manages a cluster and notices several failed components.\nWhat two options does the administrator have to run all NCC checks manually? (Choose two.)"}],"options":["Using the Actions drop-down menu in the Health dashboard of Prism Element.","Running ncc health_checks run-alll on the CVM","Using the action action drop-down menu in the Health dashboard of Prism Central","Running noc health_checks run_all on the PC VM"],"goodAnswer":[0,1],"explanations":[{"txt":"\nLes justifications pour chaque réponse sont les suivantes :\n\nA. Utiliser le menu déroulant Actions dans le tableau de bord Health de Prism Element :\nCela permet à l'administrateur de lancer manuellement tous les contrôles de santé à partir de l'interface utilisateur de Prism Element.\n\nB. Exécuter ncc health_checks run-all sur le CVM :\nCela permet à l'administrateur de lancer manuellement tous les contrôles de santé en exécutant la commande sur le Controller VM (CVM).\n\nC. Utiliser le menu déroulant Actions dans le tableau de bord Health de Prism Central :\nBien que Prism Central offre de nombreuses fonctionnalités de gestion, il ne prend pas en charge directement l'exécution manuelle des contrôles de santé sur les clusters individuels.\n\nD. Exécuter ncc health_checks run_all sur la machine virtuelle PC :\nNutanix Cluster Check (NCC) est une commande qui s'exécute sur les CVMs, pas sur les machines virtuelles Prism Central.\n\nEn résumé, les options A et B sont les deux moyens appropriés pour exécuter manuellement tous les contrôles de santé sur un cluster Nutanix."}],"id":52},{"question":[{"txt":"A newly-hired Nutanix administrator was tasked by the CIO to create a single VM on a test network. The network administrator stated that a native VLAN was used on the Cisco TOR switches with the following parameters:\nIP address: 172.16.1.2\nNetwork Mask: 255.255.255.0\nDefault gateway: 172.16.1.1\nVLAN:1\nThe same parameters were used to create a network profile on Nutanix, but the when the VM was on …\nWhat should the Nutanix administrator do to fix this issue?\n"}],"options":["Nutanix removed support for native VLAN.","Change VLAN field from vlan. 1 to vlan.0.","Enable IPv6 on the VM.","Use DHCP as opposed to static IP"],"goodAnswer":[1],"explanations":[{"txt":"La raison pour laquelle cette action est nécessaire est que, sur certains équipements réseau Cisco, le VLAN natif est généralement désigné par le numéro VLAN 0, pas par le numéro VLAN 1. Par conséquent, pour que le réseau Nutanix corresponde à la configuration réseau du commutateur Cisco, il est nécessaire de spécifier le VLAN natif comme vlan.0 dans le profil réseau Nutanix. Cela permettra au VM de se connecter correctement au réseau. Les autres options ne sont pas pertinentes pour résoudre ce problème spécifique."}],"id":53},{"question":[{"txt":"An administrator needs to provide access for a user to view real-time performance metric for all VMs on all clusters across the datacenter.\nWhich method accomplishes this with the least effort and ongoing maintenance?"}],"options":["Configure IDP authentication and assign the user to the Cluster Admin role in Prism Central.","Configure AD authentication and assign the user to the Viewer role in Prism Element.","Configure AD authentication create a custom role, assign the user to the role, and apply the role to all clusters and VMs"],"goodAnswer":[2],"explanations":[{"txt":"La réponse C est en effet la méthode qui demande le moins d'effort et de maintenance continue pour fournir l'accès à un utilisateur pour afficher les performances en temps réel de toutes les VM sur tous les clusters dans le datacenter. Voici pourquoi :\n\nA. Configurer l'authentification IDP et attribuer l'utilisateur au rôle d'administrateur de cluster dans Prism Central :\nCette option accorderait à l'utilisateur des autorisations étendues en tant qu'administrateur de cluster, ce qui peut être excessif pour simplement visualiser les performances des VM. De plus, la configuration de l'authentification IDP peut nécessiter plus d'efforts et de maintenance.\n\nB. Configurer l'authentification AD et attribuer l'utilisateur au rôle de spectateur dans Prism Element :\nCette option limite les autorisations de l'utilisateur à Prism Element seulement, mais cela peut nécessiter plus de maintenance si l'utilisateur doit également être autorisé à voir les performances sur plusieurs clusters.\n\nC. Configurer l'authentification AD, créer un rôle personnalisé, attribuer l'utilisateur au rôle, et appliquer le rôle à tous les clusters et VMs :\nCette option permet de créer un rôle personnalisé spécifiquement pour l'affichage des performances des VM, sans accorder d'accès excessif. En attribuant ensuite ce rôle à l'utilisateur et en l'appliquant à tous les clusters et VMs nécessaires, l'effort initial est minimisé et la maintenance continue est réduite car les autorisations sont gérées de manière centralisée."}],"id":54},{"question":[{"txt":"When a configuring a syslog server in Prism Central, what two pieces information are required? (Choose\ntwo.)"}],"options":["HTTPS URL","Encryption secret","Transport protocol","IP address/port"],"goodAnswer":[2,3],"explanations":[{"txt":"doc : \nConfiguring Syslog Monitoring"},{"img":"1711380159434.png"}],"id":55},{"question":[{"txt":"Upon logging into Prism Central, an administrator notices high cluster latency.\nHow can the administrator analyze data with the least number of steps or actions?\n"}],"options":[" Modify Data Density in the main Prism Central dashboard.","Click on the chart in the widget to expand the data elements.","Take note of the duster name and create a new Analysis chart","Click the cluster name in the cluster quick access widget."],"goodAnswer":[1],"explanations":[{"txt":"La réponse B est la meilleure option pour analyser les données avec le moins de démarches ou d'actions nécessaires. Voici pourquoi :\n\nA. Modifier la densité des données dans le tableau de bord principal de Prism Central :\nCela ajusterait simplement la façon dont les données sont présentées dans le tableau de bord, mais ne permettrait pas une analyse détaillée des données de latence spécifiques à un cluster.\n\nC. Prendre note du nom du cluster et créer un nouveau graphique d'analyse :\nCela nécessiterait des étapes supplémentaires pour créer un nouveau graphique d'analyse, ce qui n'est pas nécessaire pour simplement analyser les données existantes.\n\nD. Cliquer sur le nom du cluster dans le widget d'accès rapide au cluster :\nCela vous emmènerait directement à la page du cluster, ce qui est utile si vous avez besoin d'informations plus détaillées sur le cluster, mais cela ne vous donne pas immédiatement une vue détaillée des données de latence.\n\nB. Cliquer sur le graphique dans le widget pour développer les éléments de données :\nCela permettrait à l'administrateur d'accéder directement aux données détaillées sur la latence du cluster en un seul clic, offrant ainsi une analyse rapide et efficace sans avoir besoin de naviguer à travers plusieurs pages ou widgets."}],"id":56},{"question":[{"txt":"An administrator is tasked with configuring network on an AHV cluster and wants to maximize\nthroughput for the host with many small VMs while minimizing network switch configuration.\nWhich bond mode should the administrator select?"}],"options":["Active-active","Active-Active with Mac Pinning"," Active-Backup","No-Uplink Bond"],"goodAnswer":[0],"explanations":[{"txt":"With link aggregation negotiated by LACP, multiple links to separate physical switches appear as a single layer 2 link. A traffic-hashing algorithm such as balance-tcp can split traffic between multiple links in active-active mode. Because the uplinks appear as a single layer 2 link, the algorithm can balance traffic among bond members without regard for switch MAC address tables. Nutanix recommends using balance-tcp when you have LACP and link aggregation configured, because each TCP or UDP stream from a single VM can potentially use a different uplink in this configuration. The balance-tcp algorithm hashes traffic streams by source IP, destination IP, source port, and destination port. With link aggregation, LACP, and balance-tcp, a single VM with multiple TCP or UDP streams can use up to 20 Gbps of bandwidth in an AHV node with two 10 GbE adapters."},{"img":"1711380597139.png"}],"id":57},{"question":[{"txt":"Which component is supported by Prism Central storage policies?"}],"options":["Virtual Machines","Volume Groups","VM Templates","Storage Containers"],"goodAnswer":[1],"explanations":[{"txt":"La réponse correcte est D. Les politiques de stockage de Prism Central prennent en charge les conteneurs de stockage. Les conteneurs de stockage sont des entités logiques utilisées pour organiser et gérer l'espace de stockage dans un cluster Nutanix. Les politiques de stockage définissent les paramètres de stockage pour ces conteneurs, tels que la réplication, la déduplication, la compression, etc. Les politiques de stockage s'appliquent aux conteneurs de stockage plutôt qu'aux autres composants énumérés dans les options."}],"id":58},{"question":[{"txt":"An administrator would like to leverage the Reliable Event Logging Protocol (RELP) with their Remote\nSyslog Server. After completing the configuration, it is observed that RELP logging is not working as\nexpected.\nWhat is the likely cause of this issue?"}],"options":["The cluster does not have RELP installed.","The GENESIS was the only one chosen to forward log information.","The Remote Syslog Server was configure using TCP as the protocol.","The remote server does not have rsyslog-relp installed."],"goodAnswer":[3],"explanations":[{"txt":"La réponse D est correcte. Si le protocole de journalisation RELP (Reliable Event Logging Protocol) n'est pas utilisé comme prévu, une cause probable pourrait être que le serveur distant n'a pas installé le package rsyslog-relp. RELP est une extension du protocole syslog conçu pour fournir une livraison fiable des messages de journal. Si le serveur distant n'est pas configuré pour prendre en charge RELP, la journalisation avec ce protocole ne fonctionnera pas correctement.\n\nLors de \"Configuring Syslog Monitoring\":\nhttps://portal.nutanix.com/page/documents/details?targetId=Prism-Central-Admin-Center-Guide-vpc_2023_4:mul-syslog-server-configure-pc-t.html\n\nIl faut cocher la case \"Enable RELP (Reliable Event Logging Protocol)\"\n\nSelect the Enable RELP (Reliable Event Logging Protocol) checkbox to enable RELP. This step is optional.\nReliable Event Logging Protocol (RELP) is a networking protocol for data logging in computer networks. It extends the functionality of the syslog protocol to provide reliable delivery of event messages."}],"id":59},{"question":[{"txt":"Which two predefined views can be added to a report to identify inefficient VMs?"}],"options":["Underprovisioned VMs List","Zombie VMs List","Constrained VMs List","Overprovisioned VMs List"],"goodAnswer":[3,2],"explanations":[{"txt":"Doc :\nhttps://portal.nutanix.com/page/documents/details?targetId=Intelligent-Operations-Guide-vpc_2023_4:ssp-pre-define-system-report-config-c.html"},{"img":"1711381784991.png"}],"id":60},{"question":[{"txt":"When a VM is connected to a Nutanix managed network, when is the IP addressed assigned?\n"}],"options":[" When the vNIC is created on the VM.","When the VM is powered on.","When the guest OS sends a DHCP request.","When the guest OS receives a DHCP acknowledge."],"goodAnswer":[0],"explanations":[{"txt":"DANS LA DOC :\nHost Network Management\n\nManaged Networks (Layer 3)\nA virtual network can have an IPv4 configuration, but it is not required. A virtual network with an IPv4 configuration is a managed network; one without an IPv4 configuration is an unmanaged network. A VLAN can have at most one managed network defined. If a virtual network is managed, every NIC is assigned an IPv4 address at creation time.\n\nA managed network can optionally have one or more non-overlapping DHCP pools. Each pool must be entirely contained within the network's managed subnet.\n\nIf the managed network has a DHCP pool, the NIC automatically gets assigned an IPv4 address from one of the pools at creation time, provided at least one address is available. Addresses in the DHCP pool are not reserved. That is, you can manually specify an address belonging to the pool when creating a virtual adapter. If the network has no DHCP pool, you must specify the IPv4 address manually.\n\nAll DHCP traffic on the network is rerouted to an internal DHCP server, which allocates IPv4 addresses. DHCP traffic on the virtual network (that is, between the guest VMs and the Controller VM) does not reach the physical network, and vice versa.\n\nA network must be configured as managed or unmanaged when it is created. It is not possible to convert one to the other."},{"img":"1711382378833.png"}],"id":61},{"question":[{"txt":"Which two capabilities does IPAM provide in a Nutanix networking configuration? (Choose two.)"}],"options":["Allows proxy server settings to be set up for a defined network","Allows AHV to assign IP addresses automatically to VMs using DHCP","Configures a VLAN with an IP subnet and assigns a group of IP addresses","Configures firewall rules to prevent or allow certain TCP/IP traffic"],"goodAnswer":[1,2],"explanations":[{"txt":"DOC : \nNutanix AHV IP Address Management\nhttps://portal.nutanix.com/page/documents/solutions/details?targetId=BP-2071-AHV-Networking:nutanix-ahv-ip-address-management.html\n\nWith IP Address Management (IPAM), Nutanix AHV can assign IP addresses automatically to VMs using DHCP. Administrators can configure each virtual network with a specific IP subnet, associated domain settings, and IP address pools available for assignment to VMs."}],"id":62},{"question":[{"txt":"Which method can be used to migrate a VM configured for UEFI-boot from a Nutanix Hyper-V cluster to AHV?"}],"options":["Live Migration","Storage vMotion","Nutanix Move","Cloud Connect"],"goodAnswer":[2],"explanations":[{"txt":"C'est Nutanix Move ! doc : https://portal.nutanix.com/page/documents/solutions/details?targetId=TN-2072-AHV-Migration:nutanix-move.html\n\nA. Live Migration : Live Migration est une fonctionnalité de Microsoft Hyper-V qui permet de déplacer une machine virtuelle d'un hôte Hyper-V à un autre sans arrêt de la machine virtuelle. Cependant, Live Migration ne prend pas en charge la migration entre les hyperviseurs Hyper-V et AHV.\n\nB. Storage vMotion : Storage vMotion est une fonctionnalité de VMware vSphere qui permet de déplacer des machines virtuelles entre des magasins de données sans interruption de service. Comme pour Live Migration, Storage vMotion ne prend pas en charge la migration entre Hyper-V et AHV.\n\nD. Cloud Connect : Cloud Connect est une fonctionnalité de Nutanix qui permet de sauvegarder des machines virtuelles sur un stockage cloud public, tel que AWS ou Azure. Il ne s'agit pas d'un outil de migration de VM entre les hyperviseurs."}],"id":63},{"question":[{"txt":"An administrator needs to report on any alerts generated by a Nutanix cluster that affected the cluster's\navailability over the past 10 days.\nWhich method should be used to locate these events?"}],"options":["On the Health dashboard, use the Log Collector to export data based on time stamp.","Export the cluster event log to a CSV on the Alerts dashboard.","On the Alerts dashboard, filter based on Impact Type and the desired Time Range.","Configure an Alert Policy to generate an email with the data on the Health dashboard."],"goodAnswer":[2],"explanations":[{"txt":"doc :\nAlert and Event Monitoring (Prism Central)"}],"id":64},{"question":[{"txt":"CPU utilization climbs above 90% on several VMs. This causes performance degradation for a businesscritical application.\nHow can alerts be configured to notify the administrator before VM CPU utilization hits 90%?"}],"options":["On a CVM, use ncli to set the VM CPU Check threshold for the critical VMs to a value below 90%.","On the Health dashboard, locate the VM CPU Check and lower the alert threshold below 90%.","On a CVM, configure a cron job to run the VM CPU Check more frequently and email the result.","On a CVM, configure a cron job to run the VM CPU Check more frequently and email the result. D. On the Alerts dashboard, ensure that the VM CPU usage alert is not set to auto-resolve."],"goodAnswer":[1],"explanations":[{"txt":"La réponse B est la plus appropriée pour configurer des alertes pour notifier l'administrateur avant que l'utilisation du processeur de la VM n'atteigne 90%. Voici pourquoi les autres options ne sont pas les meilleures :\n\nA. Utiliser ncli sur un CVM pour définir le seuil de vérification du CPU de la VM : Bien que cela puisse techniquement être possible, il est préférable de configurer les alertes via Prism pour une gestion centralisée et conviviale.\n\nC. Configurer un travail cron sur un CVM pour exécuter la vérification du CPU de la VM : Cela implique une configuration supplémentaire complexe et ne permet pas une gestion centralisée des alertes.\n\nD. S'assurer que l'alerte d'utilisation du CPU de la VM n'est pas définie pour se résoudre automatiquement : Cette option ne concerne que la résolution automatique des alertes et ne se concentre pas sur la configuration initiale des alertes pour notifier l'administrateur avant que le seuil ne soit atteint.\n\nDoc : \nhttps://portal.nutanix.com/page/documents/details?targetId=Web-Console-Guide-Prism-v6_7:wc-health-management-wc-c.html"}],"id":65},{"question":[{"txt":"In Files, how many FSVMs are deployed by default?"}],"options":["1","2","3","5"],"goodAnswer":[2],"explanations":[{"txt":"Introduction to Nutanix Files :\nhttps://portal.nutanix.com/page/documents/details?targetId=Files-v4_4:fil-file-server-wc-c.html"},{"img":"1711449036726.png"}],"id":66},{"question":[{"txt":"A two-node ROBO cluster is configured with a witness VM."},{"img":"1711449163656.png"},{"txt":"What happens when Node A goes down?"}],"options":["The- cluster becomes unavailable and goes into read-only mode.","All operations and services on the Node B are shut down and go into a waiting state.","The cluster is unaffected and no administrator intervention is required.","Node B sends a leadership request to the Witness VM and goes into single-node mode."],"goodAnswer":[3],"explanations":[{"txt":"Failure and Recovery Scenarios :\nhttps://portal.nutanix.com/page/documents/details?targetId=Web-Console-Guide-Prism-v6_7:wc-cluster-two-node-recovery-procedures-r.html\n\nNode Failure\nWhen a node goes down, the live node sends a leadership request to the Witness VM and goes into single-node mode. In this mode RF2 is still retained at the disk level, meaning data is copied to two disks. (Normally, RF2 is maintained at the node level normally meaning data is copied to each node.) If one of the two metadata SSDs fails while in single-node mode, the cluster (node) goes into read-only mode until a new SSD is picked for metadata service. When the node that was down is back up and stable again, the system automatically returns to the previous state (RF2 at the node level). No user intervention is necessary during this transition.\n"}],"id":67},{"question":[{"txt":"How will an HDD failure affect VMs with data on the failed device?"}],"options":[" The VMs will crash, and will be restarted once the failed HDD has been replaced and the data has been restored.","A live migration will be initiated, moving the affected VMs to a host that contains the replica data.","The VMs will remain operational on that host and continue to function normally with no noticeable Impact","An HA event will occur, causing the affected VMs to restart on a node that contains the replica data."],"goodAnswer":[2],"explanations":[{"txt":"La réponse C est la plus appropriée. Lorsqu'un disque dur (HDD) échoue dans un cluster Nutanix, les VMs qui ont leurs données sur le périphérique défaillant resteront opérationnelles sur ce nœud spécifique. Cela est dû à la redondance des données sur d'autres disques du cluster, ainsi que à la capacité de Nutanix de tolérer et de gérer les pannes matérielles sans perturbation notable pour les charges de travail des VMs."}],"id":68},{"question":[{"txt":"A guest VM should be able to tolerate simultaneous failure of two nodes or drives.\nWhat are the minimum requirements for the Nutanix cluster?"}],"options":["3 nodes with cluster RF 3 and container RF 3","3 nodes with cluster RF 3 and container RF 2","5 nodes with cluster RF 2 and container RF 3","5 nodes with cluster RF 3 and container RF 3"],"goodAnswer":[3],"explanations":[{"txt":"Replication factor 3 - 5 racks (6, with Erasure Coding), 1 node in each rack"}],"id":69},{"question":[{"txt":"Which three cluster operations require an administrator to reclaim licenses?(Choose three)"}],"options":["Destroy a cluster.","Upgrade a cluster","Migrate a cluster","Remove a Node from a cluster","Move Nodes between clusters."],"goodAnswer":[0,3,4],"explanations":[{"txt":"Doc : \nLicensing Actions by Manually Managing Licenses"},{"txt":"Rebalance Your Licenses After a Cluster Change\nIf you have changed your cluster, download and apply a new licensing summary file (LSF) to help ensure your available licenses (including licensed add-ons) are applied correctly. Rebalance your cluster if you:\n\nHave added a node and have an available license in your account\nHave removed one or more nodes from your cluster. Reclaim the now-unused license and return it to your license inventory\nMove nodes from one cluster to another\nHave reduced in capacity in your cluster (number of nodes, Flash storage capacity, number of licenses, and so on)"},{"txt":"Unlicense Your Cluster to Return Licenses to Your Inventory (Also Known as Reclaiming)\nUnlicense a cluster (including licensed add-ons) to remove the licenses from a cluster and returns them to your license inventory. This action is sometimes referred to as reclaiming licenses. You also download and apply a new LSF in this case.\n\nBefore destroying a cluster, you must unlicense your cluster to reclaim and return your licenses to your inventory.\nYou do not need to reclaim legacy-licensed life of device AOS Starter licenses for Nutanix and OEM AOS Appliance platforms. These licenses are embedded and are automatically applied whenever you create a cluster. You do need to reclaim AOS Pro and Ultimate licenses for these platforms.\nYou do need to reclaim licenses (Starter / Pro / Ultimate) for software-only and third-party hardware platforms."}],"id":70},{"question":[{"txt":"When configuring Prism Central, which two log modules are able to forward messages to an external\nsyslog server? (Choose two.)"}],"options":["API Audit","Flow","DNS","NTP Synchronization"],"goodAnswer":[0,1],"explanations":[{"txt":"DOC : Configuring Syslog Monitoring\n\nhttps://portal.nutanix.com/page/documents/details?targetId=Prism-Central-Admin-Center-Guide-vpc_2023_4:mul-syslog-server-configure-pc-t.html"},{"img":"1711450558015.png"}],"id":71},{"question":[{"txt":"An administrator has been alerted to a VM that has high I/O latency and wants to determine if there are\nany other factors, such as insufficient network or memory resources that correlate, as part of a\ntroubleshooting process.\nWhich type of chart should the administrator create to allow all relevant data to be easily exported to\nCSV for later analysis?"}],"options":["A VM entity chart with each of the relevant metrics.","A cluster metric chart for each of the relevant metrics","A cluster entity chart with each of the relevant metrics","A VM metric chart for each of the relevant metrics"],"goodAnswer":[3],"explanations":[{"txt":"La réponse D est la plus appropriée. En créant un graphique basé sur les métriques de la VM, l'administrateur peut inclure toutes les métriques pertinentes pour cette VM spécifique, telles que l'utilisation du réseau, l'utilisation de la mémoire, le temps de latence d'E/S, etc. Ces métriques peuvent être facilement exportées vers un fichier CSV pour une analyse ultérieure, ce qui permet à l'administrateur de visualiser et de comparer les données de manière efficace.\n\nAn entity chart monitors the performance of one or more metrics for a single entity.\nA metric chart monitors the performance of a single metric for one or more entities."}],"id":72},{"question":[{"txt":"How should an administrator correct an SSL error when connecting to a Nutanix cluster?\n"}],"options":["Add the SSL certificate to the workstation’s trusted people store"," Create a new self-signed certificate for the cluster with a 4096 bit key","Create a new SSL certificate for the cluster signed by an AD certificate authority","Add the SSL certificate to an AD group policy applied to all computer objects"],"goodAnswer":[2],"explanations":[{"txt":"SSL Certificate Management:\nhttps://portal.nutanix.com/page/documents/details?targetId=Nutanix-Security-Guide-v6_7:mul-security-certificate-management-pc-c.html\n\nPrism Central supports SSL certificate-based authentication for console access. To enable secure communication with a cluster, Prism Central includes a default self-signed SSL certificate. You can replace the default self-signed SSL certificate with your own self-signed SSL certificate or a certificate authority (CA) signed SSL certificate.\n\nFor production purposes, Nutanix recommends that you replace the default self-signed certificate with a CA signed SSL certificate."}],"id":73},{"question":[{"txt":"A node with Erasure Coding fails.\nWhat is the impact?"}],"options":["The node stops utilizing Erasure Coding.","Potentially increased amount of data stored in the SSD tier.","Increased Controller VM CPU Load.","AQS unable to do deduplication during the Erasure Coding failure."],"goodAnswer":[2],"explanations":[{"txt":"Lorsqu'un nœud avec Erasure Coding échoue, la charge CPU des Controller VMs (CVMs) peut effectivement augmenter en raison de l'activité de redistribution des données et de la reconstruction des données sur les autres nœuds du cluster.\n\nL'Erasure Coding utilise des algorithmes de calcul intensifs pour générer des blocs de parité et reconstruire les données en cas de panne de nœud. Lorsqu'un nœud avec Erasure Coding échoue, les CVMs sur les autres nœuds doivent effectuer des calculs supplémentaires pour redistribuer les données et régénérer les blocs de parité afin de maintenir la redondance et l'intégrité des données.\n\nAinsi, la réponse C, \"Increased Controller VM CPU Load\", est en effet justifiée."}],"id":74},{"question":[{"txt":"An administrator has created a Nutanix managed it a VLAN ID of 512.\nA configuration is single domain, single forest, and does not use SSL.\nWhich port number should be used to configure LDAP?"}],"options":["389","3269","636","3268"],"goodAnswer":[0],"explanations":[{"txt":"The default LDAP port number is 389."}],"id":75},{"question":[{"txt":"The Linux administration team has requested access rights to any current or future Linux VM in the\nenvironment\nWhat entity should be selected when assigning this new role?\n"}],"options":["Image","AHV Cluster","Category","Project"],"goodAnswer":[3],"explanations":[{"txt":"Environments in Projects\nhttps://portal.nutanix.com/page/documents/details?targetId=Prism-Central-Admin-Center-Guide-vpc_2023_4:ssp-environment-overview-c.html"}],"id":76},{"question":[{"txt":"What is the proper sequence to perform a one-click upgrade to a Nutanix cluster?\nItem instructions: For each procedure, indicate the order in which that procedure must take place to\nmeet the item requirements. Not all procedures are valid. Identify any invalid procedures using the dropdown option."},{"img":"1711453846035.png"}],"options":["Step 1 : Login into Prism Element. Step 2 : Select the Gear Icon at top right of the page. Step 3 : Click Upgrade Software. Step 4 : Select the component to upgrade. Step 5 : Click download. Step 6 : Once the download completes, select upgrade.","Step 1: Select the Gear Icon at top right of the page. Step 2: Click Upgrade Software. Step 3: Once the download completes, select upgrade. Step 4: Login into Prism Element. Step 5: Click download. Step 6: Select the component to upgrade.","Step 1: Click Upgrade Software. Step 2: Select the component to upgrade. Step 3: Once the download completes, select upgrade. Step 4: Login into Prism Element. Step 5: Select the Gear Icon at top right of the page. Step 6: Click download.","Step 1: Select the component to upgrade. Step 2: Once the download completes, select upgrade. Step 3: Click Upgrade Software. Step 4: Login into Prism Element. Step 5: Select the Gear Icon at top right of the page. Step 6: Click download."],"goodAnswer":[0],"explanations":[{"txt":"Step 1 ---> Login into Prism Element.\nStep 2 ---> Select the Gear Icon at top right of the page.\nStep 3 ---> Click Upgrade Software.\nStep 4 ---> Select the component to upgrade.\nStep 5 ---> Click download.\nStep 6 ---> Once the download completes, select upgrade.\nInvalid:-\n1 - Select Prism Central.\n2 - Select user login.\n3 - On left select upgrade Prism Central."}],"id":77},{"question":[{"txt":"A customer wants to isolate a group of VMs within their Nutanix environment for security reasons. The\ncustomer creates a VM with two NICs to act as a firewall and installs the appropriate software and\ncertificates.\nHowever, no one from the outside can access the application.\nWhat is the likely cause of this problem?\n\n"}],"options":["A shared volume group must be used by all isolated VMs","More than one NIC cannot be added to a VM","One of the NICs needs to be configured on the internal VLAN","Wireshark is installed on the NAT VM"],"goodAnswer":[2],"explanations":[{"txt":"A. Un groupe de volumes partagé n'est pas nécessairement requis pour isoler les VMs. Cette réponse est incorrecte car elle ne résout pas le problème de l'accès à l'application depuis l'extérieur.\n\nB. Il est tout à fait possible d'ajouter plus d'une NIC à une VM. Cependant, dans ce cas, cela ne semble pas être le problème principal empêchant l'accès à l'application depuis l'extérieur.\n\nC. Cette réponse est correcte. Lorsqu'une VM agit en tant que pare-feu, elle doit avoir une NIC connectée au réseau externe (où les utilisateurs accèdent à l'application) et une autre NIC connectée au réseau interne (où résident les VMs isolées). Si les deux NIC sont configurées sur le VLAN externe, le pare-feu peut bloquer tout accès externe à l'application, ce qui est probablement la cause du problème observé.\n\nD. La présence de Wireshark sur la VM NAT n'est pas directement liée au problème d'accès à l'application depuis l'extérieur. Cette réponse est donc incorrecte.\n\nEn résumé, la réponse la plus probable est la réponse C, car configurer l'une des NICs sur le VLAN interne permettra au pare-feu de gérer le trafic entre les réseaux externe et interne, permettant ainsi l'accès externe à l'application tout en maintenant l'isolation des VMs internes."}],"id":78},{"question":[{"txt":"Which two methods are available when migrating a VM from a legacy 3-tier solution using VMware ESXi\nto AHV? (Choose two.)\n"}],"options":["Deploy the Move appliance.","Use Cross-Hypervisor DR.","Import the .vmdk into the Image Service.","Use shared nothing live migration."],"goodAnswer":[0,1],"explanations":[{"txt":"https://portal.nutanix.com/page/documents/solutions/details?targetId=TN-2072-AHV-Migration:nutanix-move.html\nhttps://portal.nutanix.com/page/documents/details?targetId=Prism-Element-Data-Protection-Guide-v6_7:wc-dr-cross-hypervisor-c.html"}],"id":79},{"question":[{"txt":"A customer has a 24-node cluster with all containers configured with RF3. Two different nodes have\nincurred a simultaneous HDD failure.\nWhat is the result?"}],"options":["The cluster runs in a degraded state until the failed drives are replaced and the data has been restored to three replicas.","Sixty minutes after the failures a rebuild of the lost data can remaining HDDs begins to restore to three replicas.","The VMs with data on those drives crash, and an HA event occurs, restarting them on a remaining healthy node.","The Nutanix cluster recognizes the failures and immediately begins to rebuild lost data to three replicas."],"goodAnswer":[3],"explanations":[{"txt":"A. La cluster fonctionne dans un état dégradé jusqu'à ce que les disques défaillants soient remplacés et que les données aient été restaurées à trois répliques.\nCette réponse est incorrecte car lorsque deux disques subissent une défaillance simultanée dans une configuration RF3, le cluster ne fonctionne pas dans un état dégradé. Au contraire, il reconnaît automatiquement les pannes et commence à reconstruire les données perdues sans interruption du service.\n\nB. Soixante minutes après les pannes, une reconstruction des données perdues sur les disques restants commence pour restaurer trois répliques.\nCette réponse est incorrecte car le processus de reconstruction des données commence immédiatement après la détection des pannes, et il n'y a pas de délai de soixante minutes spécifié dans ce contexte.\n\nC. Les VM avec des données sur ces disques plantent, et un événement HA se produit, les redémarrant sur un nœud sain restant.\nCette réponse est incorrecte car dans une configuration RF3, les données sont suffisamment redondantes pour éviter une perte de service en cas de défaillance de deux disques sur différents nœuds. Les VMs continueront à fonctionner normalement car les données sont toujours accessibles via d'autres répliques.\n\nD. Le cluster Nutanix reconnaît les pannes et commence immédiatement à reconstruire les données perdues pour atteindre trois répliques.\nCette réponse est correcte car dans une configuration RF3, le cluster est conçu pour maintenir trois répliques de données, et il commence automatiquement à reconstruire les données perdues pour assurer la redondance et la disponibilité des données."}],"id":80},{"question":[{"txt":"An Administrator is working on a one-node ROBO cluster configurations\nWhich statement is true for this configuration?"}],"options":[" Witness vm required to break cluster quoram","Supported hardware is NX-1175-G5 and G6","witness vm should be 8vcp and 20gb ram","the minimum RPO 8 hours required"],"goodAnswer":[1],"explanations":[{"txt":"System Specifications for Single-Node G6 Platforms\nhttps://portal.nutanix.com/page/documents/details?targetId=System-Specs-G6-Single-Node:System-Specs-G6-Single-Node"}],"id":81},{"question":[{"txt":"In which two scenarios is an automated live migration likely to occur? (Choose two)\n"}],"options":["Cluster resource hotspot","AOS upgrade","Network upgrade","Hypervisor upgrade"],"goodAnswer":[0,3],"explanations":[{"txt":"Live Migration Cases\nhttps://portal.nutanix.com/page/documents/details?targetId=Prism-Central-Guide-vpc_2023_4:mul-vm-live-migration-cases-c.html"}],"id":82},{"question":[{"txt":"An administrator wants to create a trunked interface on a VM on AOS 5.15x.\nWhich two steps should the administrator take first to achieve this? (Choose two)"}],"options":["Use acli","Log in over PE web UI","SSH to CVM","Update VM dialog"],"goodAnswer":[0,2],"explanations":[{"txt":"Enable VLAN trunking on Nutanix AHV VM\nhttps://www.vmwaremine.com/2019/05/09/enable-vlan-trunking-on-nutanix-ahv-vm/#sthash.3uIAHeXZ.dpbs"}],"id":83},{"question":[{"txt":"What is the default network bond setting for an AHV host configuration?"}],"options":["active-backup","active-active","balance-slb"," balance-tcp"],"goodAnswer":[0],"explanations":[{"txt":"Configuring Load Balancing active-backup and balance-slb modes on AHV\n\nhttps://portal.nutanix.com/page/documents/kbs/details?targetId=kA00e000000Xf2qCAC\n\n\"The default bond mode is active-backup.\""}],"id":84},{"question":[{"txt":"Which best practice should be followed when creating a bond in a Nutanix cluster?"}],"options":["Place NICs of different speeds within the same bond","Configure the bond to use LACP","Only utilize NICs of the same speed within the same bond","Use the default bond configuration after installation"],"goodAnswer":[1],"explanations":[{"txt":"OVS Bonds\nhttps://portal.nutanix.com/page/documents/solutions/details?targetId=BP-2071-AHV-Networking:ovs-bonds.html"}],"id":85},{"question":[{"txt":"When VM HA Reservation is enabled, what is the expected behavior for all failed VMs in the event of a\nhost failure?"}],"options":["Restart on a best-effort basis if resources are available","Perform a live migration to other hosts in the AHV cluster","Restart on other hosts in the AHV cluster","Perform a live migration on a best-effort basis if resources are available"],"goodAnswer":[2],"explanations":[{"txt":"AHV VM High Availability (VM HA) feature ensures VM availability in case of a host failure. In the event of a host failure, the VMs previously running on the failed host will be restarted on other healthy hosts throughout the cluster. The Acropolis leader CVM is responsible for failing over the VM(s) on the healthy host(s).\n\nhttps://portal.nutanix.com/page/documents/kbs/details?targetId=kA00e000000LIQUCA4"}],"id":86},{"question":[{"txt":"Which three upgrades should an administrator be able to perform using Lifecycle Management? (Choose Three)\n"}],"options":["AOS","BMC","BIOS","Hypervisor","HBA Firmware"],"goodAnswer":[1,2,4],"explanations":[{"txt":"Basically, all firmware updates performed through LCM require the hosts to boot into a CentOS-based staging area called Phoenix with the following exceptions.\nCertain modules for Dell platforms.\nLCM 2.3.2 onwards, for DISK firmware, LCM utilizes IVU based update mechanism which does not require the host reboot.\nLCM 2.4.0 onwards, for BIOS and BMC firmware, when certain conditions are met, LCM utilizes Redfish update mechanism which does not require the host reboot.\nhttps://portal.nutanix.com/page/documents/kbs/details?targetId=kA00e000000LMgICAW"}],"id":87},{"question":[{"txt":"An administrator has set up a local web server accessible to the Nutanix clusters.\nWhich two steps are required to set up LCM for an environment without Internet access? (Choose two.)\n"}],"options":[" Download the lcai_disconnecced_version. tar.gz LCM bundle from the support portal.","Edit LCM Advanced Settings in Prism Element and enter the address of the web server.","Edit LCM Advanced Settings m Prism Central and enter the address of the web server.","Download the lcm_dark_site_version. tar . gz LCM bundle from the support portal."],"goodAnswer":[1,3],"explanations":[{"txt":"A. Téléchargez le fichier tar.gz de la version déconnectée de LCM à partir du portail de support.\nCette réponse est incorrecte car bien que télécharger le bundle LCM depuis le portail de support soit nécessaire, la version spécifique à télécharger pour une utilisation sans accès Internet est le bundle dark_site, pas le bundle disconnected_version.\n\nB. Modifier les paramètres avancés de LCM dans Prism Element et saisir l'adresse du serveur Web.\nCette réponse est correcte car pour configurer LCM dans un environnement sans accès Internet, vous devez spécifier l'adresse du serveur Web local où se trouve le bundle LCM. Cela permet à LCM de télécharger et d'appliquer les mises à jour depuis le serveur local.\n\nC. Modifier les paramètres avancés de LCM dans Prism Central et saisir l'adresse du serveur Web.\nCette réponse est incorrecte car la configuration des paramètres avancés de LCM dans Prism Central n'est pas nécessaire pour un déploiement sans accès Internet. L'adresse du serveur Web doit être spécifiée dans Prism Element, pas dans Prism Central.\n\nD. Téléchargez le fichier tar.gz de la version dark_site de LCM à partir du portail de support.\nCette réponse est correcte car pour un déploiement sans accès Internet, vous devez télécharger la version dark_site du bundle LCM, qui est conçue spécifiquement pour être utilisée dans des environnements isolés."}],"id":88},{"question":[{"txt":"A cluster has RF2. The cluster loses two drives on different nodes in the same storage tier.\nWhat is the effect on the replicas of the VMs?"}],"options":["Some VM data may be lost","No VMs lose data if the node has two or more SSDs","Some VMs may reboot and gain access to data","No VMs lose data because of RF2"],"goodAnswer":[0],"explanations":[{"txt":"Par défaut, les clusters Nutanix ont un facteur de redondance (Redundancy Factor RF appelé aussi Fault Tolerance FT) égale à 2, ce qui signifie qu’ils peuvent tolérer la défaillance d’un seul nœud ou disque. Plus le cluster est grand, plus la probablité d’avoir plusieurs échecs augemente."}],"id":89},{"question":[{"txt":"Which change can be made on a cluster with software-based Data-at-Rest Encryption enabled?"}],"options":["Disable encryption on the cluster","Deploy an additional Native KMS Server","Enable encryption for a VM","Change Native KMS to External KMS"],"goodAnswer":[3],"explanations":[{"txt":"A. Désactiver le chiffrement sur le cluster\nCette réponse est incorrecte car une fois le chiffrement des données au repos activé sur un cluster, il ne peut pas être désactivé sans réimporter toutes les données non chiffrées dans le cluster.\n\nB. Déployer un serveur KMS natif supplémentaire\nCette réponse est incorrecte car le chiffrement des données au repos utilise un seul serveur KMS natif par cluster. Il n'est pas possible de déployer plusieurs serveurs KMS natifs pour un même cluster.\n\nC. Activer le chiffrement pour une VM\nCette réponse est incorrecte car le chiffrement des données au repos est une fonctionnalité du cluster qui chiffre toutes les données stockées sur le disque, pas des machines virtuelles individuelles.\n\nD. Changer de KMS natif à un KMS externe\nCette réponse est correcte car sur un cluster avec chiffrement des données au repos activé, il est possible de passer d'un KMS natif à un KMS externe. Cependant, cette opération nécessite une configuration appropriée et une coordination avec l'administrateur de la clé externe."}],"id":90},{"question":[{"txt":"An administrator is reviewing performance of a core banking system that routinely has 20,000\nconcurrent users. During, business hours, the CPU on the applications servers runs at close to 100%. The\nadministrator needs to determine if there is a performance issue specific to the app servers, the\ndatabase servers, or all servers on the cluster.\n"},{"img":"1711461288690.png"},{"txt":"Which metrics should the administrator review in Prism Analysis Graphs?\n"}],"options":["Cluster IO, Network, Database and App Server CPU","Cluster CPU and Memory Only","Cluster IO, CPU, Memory and Database and App Server CPU","Cluster IO, CPU, Memory, Network, App Server CPU"],"goodAnswer":[3],"explanations":[{"txt":"\nPour justifier la réponse correcte (D), examinons chaque option :\n\nA. Cluster IO, Réseau, CPU de la base de données et du serveur d'applications\nCette réponse est incorrecte car elle ne prend pas en compte la mémoire, qui est un aspect critique de la performance des serveurs.\n\nB. Cluster CPU et mémoire uniquement\nCette réponse est incorrecte car elle ne prend pas en compte d'autres aspects importants tels que l'E/S et le réseau, qui peuvent également affecter les performances.\n\nC. Cluster IO, CPU, Mémoire, CPU de la base de données et du serveur d'applications\nCette réponse est proche de la bonne réponse, mais elle ne mentionne pas spécifiquement le réseau, qui est également important pour évaluer les performances.\n\nD. Cluster IO, CPU, Mémoire, Réseau, CPU du serveur d'applications\nCette réponse est correcte car elle inclut tous les aspects essentiels de la performance du système : l'E/S, le CPU, la mémoire, le réseau et le CPU du serveur d'applications. Cela permettra à l'administrateur d'avoir une vue complète de la performance du système et d'identifier plus précisément les goulets d'étranglement."}],"id":91},{"question":[{"txt":"A VM in a 12-node Nutanix cluster is hosting an application that has specific Physical GPU requirements.\nOnly three nodes in the cluster meet this requirement.\nThe administrator wants to allow a general workload to be distributed across all nodes in the cluster and\nmust make sure that the node hosting the VM meets its requirements.\nHow should the administrator perform this task?"}],"options":["Create a sperate three-node cluster using the nodes that meet the requirement.","Configure VM-Host affinity for the nodes that meet the application's GPU requirement.","Over-Provision the application VM with additional virtual GPUs.","Configure anti-affinity rules between the application VM and the other VMs running on the cluster."],"goodAnswer":[1],"explanations":[{"txt":"GPU Pass-Through for Guest VMs\nhttps://portal.nutanix.com/page/documents/details?targetId=AHV-Admin-Guide-v6_7:ahv-gpu-passthrough-for-guest-vms-intro-c.html"}],"id":92},{"question":[{"txt":"Where should an administrator unregister Prism Element from Prism Central?\n"}],"options":["From a Host SSH session","From the Prism Central web console","From the Prism Element web console","From a CVM SSH session"],"goodAnswer":[3],"explanations":[{"txt":"Unregister cluster from Prism Central and cleanup (regular and force), FAQs:\n\nhttps://portal.nutanix.com/page/documents/kbs/details?targetId=kA00e000000XeZjCAK"}],"id":93},{"question":[{"txt":"How should an administrator configure a custom alert for a specific VM in Prism?\n"}],"options":["Modify an existing alert to only alert on the specific VM.","Modify VM settings to add the custom alert.","Modify the alerts to add a new custom alert policy.","Modify node settings to add the custom alert."],"goodAnswer":[2],"explanations":[{"txt":"Réponse C : Modifier les alertes pour ajouter une nouvelle politique d'alerte personnalisée.\nCette réponse est correcte car pour configurer une alerte personnalisée pour une VM spécifique dans Prism, l'administrateur doit ajouter une nouvelle politique d'alerte qui cible cette VM en particulier. Cela peut se faire en modifiant les paramètres d'alerte dans Prism pour inclure une nouvelle politique d'alerte qui surveille les métriques spécifiques de la VM ciblée.\n\nLes autres réponses ne sont pas appropriées :\n\nA : Modifier une alerte existante pour n'alerter que sur la VM spécifique n'est pas nécessairement la meilleure approche, car cela pourrait affecter d'autres VMs qui sont actuellement surveillées par cette alerte.\nB : Modifier les paramètres de la VM pour ajouter l'alerte personnalisée n'est pas possible dans Prism, car les alertes sont configurées au niveau du cluster ou du centre de données, pas au niveau de la VM individuelle.\nD : Modifier les paramètres de nœud pour ajouter l'alerte personnalisée est également incorrect, car les alertes sont configurées au niveau du cluster ou du centre de données, et les nœuds ne sont pas le niveau approprié pour configurer des alertes spécifiques aux VMs."}],"id":94},{"question":[{"txt":"Which two private key types are supported by the Nutanix SSL certificate implementation? (Choose two.)\n"}],"options":["ECDSA","ECDH","ED25519","RSA"],"goodAnswer":[0,3],"explanations":[{"txt":"Recommended Key Configurations\nhttps://portal.nutanix.com/page/documents/details?targetId=Nutanix-Security-Guide-v6_7:wc-recommended-key-combinations-prism-r.html"}],"id":95},{"question":[{"txt":"In which two scenarios is Native Key Management Server supported? (Choose two)"}],"options":["XenServer and AHV mixed cluster.","Hyper-V and AHV mixed cluster.","KVM and AHV mixed cluster.","ESXi and AHV mixed cluster."],"goodAnswer":[1,3],"explanations":[{"txt":"Data-at-Rest Encryption\n\nhttps://portal.nutanix.com/page/documents/details?targetId=Nutanix-Security-Guide-v6_7:wc-security-data-encryption-wc-c.html"}],"id":96},{"question":[{"txt":"In Nutanix clusters, which feature ensures VMs can be migrated and restarted on another host in case of\nfailure?\n"}],"options":["High Availability","Protection Domain","Host Affinity Rules","Availability Zone"],"goodAnswer":[0],"explanations":[{"txt":"https://portal.nutanix.com/kb/4636"}],"id":97},{"question":[{"txt":"HOTSPOT\nAn administrator needs to shut down an AHV cluster to relocate hardware. The administrator upgrades\nNCC and runs health checks.\nWhich steps should the administrator perform next?\nItem instructions: For each procedure, indicate the order in which that procedure must take place to\nmeet the item requirements.\n\nShut down CVMs - Step ?\n\nShut down Nodes - Step ?\n\nShut down Guest VMs - Step ?\n\nStop the Cluster - Step ?"}],"options":["1. Shut down Guest VMs 2. Stop the Cluster 3. Shut down CVMs 4. Shut down Nodes","1. Stop the Cluster 2. Shut down Guest VMs 3. Shut down Nodes 4. Shut down CVMs","1. Shut down CVMs 2. Shut down Nodes 3. Shut down Guest VMs 4. Stop the Cluster","1. Shut down Nodes 2. Stop the Cluster 3. Shut down CVMs 4. Shut down Guest VMs"],"goodAnswer":[0],"explanations":[{"txt":"https://next.nutanix.com/how-it-works-22/scheduled-power-outage-relocating-cluster-hardware-if-you-need-to-shut-down-all-the-nodes-in-your-ahv-cluster-here-s-how-37326"}],"id":98},{"question":[{"txt":"What is the expected operation during node addition when the new node has a different AOS version?\n"}],"options":["The entire cluster is upgraded to the latest one-click release.","The node is added and a separate upgrade operation must be performed.","The addition fails and forces the administrator to image using standalone Foundation.","The node is automatically re-imaged using the software currently running in the cluster."],"goodAnswer":[2],"explanations":[{"txt":"Expand a Cluster Prerequisites and Requirements\n\nhttps://portal.nutanix.com/page/documents/details?targetId=Web-Console-Guide-Prism-v6_7:wc-cluster-expand-wc-r.html"}],"id":99},{"question":[{"txt":"In a default configuration of an AHV cluster, a single node fails.\nWhat happens to the running VMs on that node?"}],"options":["The cluster restarts all VMs in the event of a host failure","The VMs do a live migration to the master node in the cluster","The VMs do a live migration to any other node in the cluster","The cluster attempts to restart VMs on other hosts"],"goodAnswer":[3],"explanations":[{"txt":"\"If you have not enabled High Availability, in case of host failure, the VMs are restarted from the failed host to any available space on the other hosts in the cluster. Once the failed host joins the cluster again, VMs are migrated back to the host. This type of VM high availability is implemented without reserving any resources. Admission control is not enforced and hence there may not be sufficient capacity available to start all the VMs.\"\n\nhttps://portal.nutanix.com/page/documents/details?targetId=AHV-Admin-Guide-v6_7:ahv-vm-management-intro-c.html"}],"id":100},{"question":[{"txt":"Where can an administrator change a CVM password?"}],"options":["KMS Server Terminal","CVM setting in Prism Elemen","CVM setting in Prism Central","Prism CVM VM Console"],"goodAnswer":[3],"explanations":[{"txt":"https://portal.nutanix.com/page/documents/kbs/details?targetId=kA00e000000LKXcCAO"}],"id":101},{"question":[{"txt":"An administrator needs to boot a VM to a bootable CD. The administrator tries to configure the VM to\nboot to it, select to add disk, and goes to the images available. The image for the bootable CD is\nunavailable.\nWhat is the Likely issue?"}],"options":["The CD-ROM interface is too slow.","The administrator selected a disk attached before it can boot to a CD.","The VM needs to have a standard disk attached before it can boot to a CD.","The bootable CD image is corrupted during creation."],"goodAnswer":[1],"explanations":[{"txt":"https://next.nutanix.com/prism-infrastructure-management-26/booting-vm-to-cd-no-drivespresent-31800"}],"id":102},{"question":[{"txt":"A Nutanix cluster is equipped with four nodes. Four VMs on this cluster have been configured with a VMVM anti-affinity policy and are each being hosted by a different node.\nWhat occurs to the cluster and these VMs during an AHV upgrade?\n"}],"options":["One node hosts two VMs while the node being upgraded is in maintenance mode.","One VM out of the four powers down when the node hosting it reboots.","The AHV pre-upgrade checks fail until the administrator disables the anti-affinity policy.","The AHV pre-upgrade checks fail until the four VMs are powered off."],"goodAnswer":[2],"explanations":[{"txt":"Affinity Policies for AHV\n\nhttps://portal.nutanix.com/page/documents/details?targetId=AHV-Admin-Guide-v6_7:ahv-affinity-policies.html"}],"id":103},{"question":[{"txt":"How many SSL certificates are used by Prism Element on a Nutanix cluster?"}],"options":["1","5","256","2048"],"goodAnswer":[0],"explanations":[{"txt":"https://portal.nutanix.com/page/documents/details?targetId=Nutanix-Security-Guide-v6_7:wc-security-ssl-certificate-wc-t.html"}],"id":104},{"question":[{"txt":"Which algorithm do snapshots and clones leverage to maximize efficiency and effectiveness?"}],"options":["Continuous Data Protection","Copy-on-Write","Split-mirror","Redirect-On-Write"],"goodAnswer":[3],"explanations":[{"txt":"Nutanix Clones and Snapshots\n\nhttps://portal.nutanix.com/page/documents/solutions/details?targetId=TN-2064-Nutanix-Clones-and-Snapshots:TN-2064-Nutanix-Clones-and-Snapshots#:~:text=Nutanix%20AOS%20distributed%20storage%20provides,that%20AOS%20presents%20to%20VMs.\n\nNutanix AOS distributed storage provides elegant clone and snapshot functionality using a redirect-on-write algorithm. vDisks at the Nutanix layer back the files that AOS presents to VMs. Each vDisk in the system is hosted, or owned, by a Nutanix node's Controller VM (CVM). The CVM typically runs on the same Nutanix node as the VM using its vDisks. vDisks are made of blocks, which are 1 MB chunks of virtual address space."}],"id":105},{"question":[{"txt":"HOTSPOT\nAsync DR is configured between two sites. A network outage occurs at the primary site.\nWhich steps must the administrator perform to bring the VMs back into service at the backup site?\nItem instructions: For each procedure, indicate the order in which that procedure must take place to\nmeet the item requirements. Not all procedures are valid. Identify any invalid procedures using the dropdown option"},{"img":"1711468135814.png"}],"options":["1. Log into Prism Element at the primary site 2. Go to the Async DR tab 3. Select the Protection Domain and Click Activate 4. Power on VMS","1. Go to the Async DR tab 2. Log into Prism Element at the primary site 3. Power on VMs 4. Select the Protection Domain and Click Activate","1. Select the Protection Domain and Click Activate  2. Power on VMs  3. Log into Prism Element at the primary site  4. Go to the Async DR tab","1. Go to the Async DR tab  2. Power on VMs  3. Log into Prism Element at the primary site  4. Select the Protection Domain and Click Activate"],"goodAnswer":[0],"explanations":[{"txt":"Remote Site Configuration\n\nhttps://portal.nutanix.com/page/documents/details?targetId=Prism-Element-Data-Protection-Guide-v6_5:wc-remote-site-any-configuration-c.html"}],"id":106},{"question":[{"txt":"What are two minimum prerequisites for live migration to succeed? (Choose two.)\n"}],"options":["All AHV hosts have IP addresses in the same subnet","All AHV hosts must be configured on the same VLAN","All VMs have an IP address in the same subnet","All VMs are configured for the same VLAN"],"goodAnswer":[0,1],"explanations":[{"txt":"Cross-Cluster Live Migration Requirements\n\nhttps://portal.nutanix.com/page/documents/details?targetId=Disaster-Recovery-DRaaS-Guide-vpc_2023_4:ecd-ecdr-requirements-cclm-recoveryplan-pc-r.html"}],"id":107},{"question":[{"txt":"When creating a VM on an AHV cluster, how is the initial placement of the VM determined?\n"}],"options":["AHV uses a round robin algorithm, placing new VMs onto hosts based on the numerical order of their UUID","The administrator right clicks on the desired host and selects Power on VM from the dropdown menu","The Acropolis Dynamic Scheduler selects a host which provides adequate resources for the VMs configuration","Placement is determined by the host that holds the new_VM token at the time of VM creation"],"goodAnswer":[2],"explanations":[{"txt":"Intelligent VM Placement\n\nWhen you create, restore, or recover VMs, the system assigns them to an AHV host in the cluster based on a recommendation from Acropolis Dynamic Scheduler. This VM placement process also takes into account the AHV cluster's high-availability configuration, so it doesn't violate any failover host or segment reservations. We explain these high-availability constructs in the Automated High Availability section."}],"id":108},{"question":[{"txt":"Which command should an administrator run from the CLI to view the uplink state of all AHV nodes in\nthe cluster?"}],"options":["allssh show_uplinks","manage_ovs show_uplinks","allssh manage_ovs show_uplinks","manage ovs show uplinks"],"goodAnswer":[2],"explanations":[{"txt":"OVS Command Line Configuration\n\nhttps://portal.nutanix.com/page/documents/solutions/details?targetId=BP-2071-AHV-Networking:ovs-command-line-configuration.html\n\nallssh\nhttps://portal.nutanix.com/page/documents/solutions/details?targetId=BP-2071-AHV-Networking:example-1-allssh.html"}],"id":109},{"question":[{"txt":"What is Prism Central primarily used for?"}],"options":["Multi-cluster network configuration","Container creation","Multi-cluster Single Sign On","Data reduction configuration"],"goodAnswer":[2],"explanations":[{"txt":"Prism Central provides a workspace to monitor and manage multiple clusters from a centralized environment. It runs as a separate instance that consists of either a single VM or as a three-VM scale-out architecture. For more information, see https://portal.nutanix.com/page/documents/details?targetId=Prism-Central-Guide-vpc_2023_4:mul-pc-scale-out-t.html"}],"id":110},{"question":[{"txt":"Which component ensures uniform distribution of data throughout the cluster to eliminate hot spots and\nspeed up rebuilds?"}],"options":["Cassandra","Distributed Storage Fabric","High Availability","Acropolis App Mobility Fabric"],"goodAnswer":[1],"explanations":[{"txt":"B. Distributed Storage Fabric : Le Distributed Storage Fabric de Nutanix est conçu pour garantir une distribution uniforme des données sur l'ensemble du cluster. Il utilise une architecture distribuée pour répartir les données de manière équilibrée sur tous les nœuds du cluster, ce qui aide à éliminer les points chauds et à accélérer la reconstruction en cas de panne."}],"id":111},{"question":[{"txt":"An administrator is configuring data protection and DR for a multi-tier application. All VMs must be\nprotected at the same time.\nWhat must the administrator do to meet this requirement?\n"}],"options":["Create a consistency group for each VM with identical schedules","Create a consistency group for the application and place all VMs in it","Create a protection domain for the application and select auto-protect related entities","Create a protection domain for each VM with identical schedules"],"goodAnswer":[2],"explanations":[{"txt":"En créant un domaine de protection pour l'application et en sélectionnant l'option \"auto-protect related entities\", l'administrateur peut s'assurer que toutes les machines virtuelles associées à l'application sont protégées en même temps. Cette option permet d'automatiser le processus de protection des données pour l'ensemble de l'application, ce qui garantit la cohérence et la synchronisation des sauvegardes et de la reprise après sinistre pour toutes les VMs concernées."}],"id":112},{"question":[{"txt":"An administrator logs in to Prism Element goes to the Network view, and sees the output shown in the exhibit"},{"img":"1711470851237.png"},{"txt":"Which three steps must the administrator take to increase throughput to the host? (Choose three.)"}],"options":["Connect the 10Gb interfaces to the physical switch.","Change the bond mode to balance-slb or balance—tcp.","Remove any 1Gb interfaces still connected from the default bond.","Add a new switch to the network and connect 1Gb interfaces to it.","Change the VLAN ID to a higher priority ID."],"goodAnswer":[0,1,4],"explanations":[{"txt":"Connect the 10Gb interfaces to the physical switch : Utiliser des interfaces 10Gb permet d'augmenter la bande passante disponible entre le serveur et le réseau, ce qui peut améliorer le débit.\nChange the bond mode to balance-slb or balance-tcp : Changer le mode de liaison (bond mode) à balance-slb ou balance-tcp peut optimiser la répartition de la charge sur les interfaces réseau, permettant ainsi d'augmenter le débit.\nChange the VLAN ID to a higher priority ID : En changeant l'identifiant VLAN (VLAN ID) à une valeur de priorité plus élevée, l'administrateur peut s'assurer que le trafic du serveur est prioritaire sur le réseau, ce qui peut contribuer à améliorer le débit global."}],"id":113},{"question":[{"txt":"AHV IPAM assigns an IP address from the address pool when creating a managed VM NIC.\nAt which two instances does the address release back to the pool? (Choose two)"}],"options":["The IP address lease expires","The VM NIC is deleted.","The IP address is changed to static.","The VM is deleted."],"goodAnswer":[1,3],"explanations":[{"txt":"Nutanix AHV IP Address Management\n\nhttps://portal.nutanix.com/page/documents/solutions/details?targetId=BP-2071-AHV-Networking:nutanix-ahv-ip-address-management.html"}],"id":114},{"question":[{"txt":"Refer to the exhibit."},{"img":"1711471933457.png"},{"txt":"Admin1 user does not have access to all Linux VMs.\nWhat step should be taken to grant the proper access?"}],"options":["Add the hosts to the entities KM for the role.","Grant the admin1 user the viewer role (or the cluster.","Add the role to the Linux images.","Add the proper category to each Linux VM."],"goodAnswer":[0],"explanations":[{"txt":"Assigning Role Permissions\n\nhttps://portal.nutanix.com/page/documents/details?targetId=Nutanix-Security-Guide-v6_7:wc-security-role-permissions-wc-t.html"}],"id":115},{"question":[{"txt":"When installing Nutanix Guest Tools (NGT) on an ESXi-hosted VM, which port should be enabled on the\nVM to allow communication with the NGT-Controller VM service?\n"}],"options":["2000","2074","8080","9943"],"goodAnswer":[1],"explanations":[{"txt":"Nutanix Guest Tools Requirements\n\nhttps://portal.nutanix.com/page/documents/details?targetId=Prism-Central-Guide-vpc_2023_4:mul-ngt-pc-requirements-r.html"}],"id":116},{"question":[{"txt":"Where are Leap Availability Zones configured?"}],"options":["Cloud Connect","Controller VM","Prism Element","Prism Central"],"goodAnswer":[3],"explanations":[{"txt":"Availability Zones View\n\nThe Availability Zones view lists all the paired AZs.\n\nTo view the paired AZs, perform the following steps:\n\nPerform one of the following based on the Prism Central-based DR solution type you plan to deploy:\nOn-prem to on-prem AZ or on-prem AZ to NC2 AZ – Log in to the Prism Central web console.\nNutanix Cloud AZ to on-prem AZ (DRaaS) – Log in to the Nutanix Cloud Services portal.\nNC2 AZ to NC2 AZ – Log in to the Prism Central web console in the NC2 cluster.\nPerform one of the following based on your choice in Step 1:\nOn-prem to on-prem AZ, on-prem AZ to NC2 AZ, or NC2 AZ to NC2 AZ – Select the Infrastructure application from Application Switcher Function, and go to Administration > Availability Zones from the Navigation Bar.\nNutanix Cloud AZ to on-prem AZ (DRaaS) – Click the Navigation icon to access the Navigation Bar, and go to Administration > Availability Zones.\nThe Availability Zones page opens, displaying all the paired AZs.\n\nThe following tables describe the fields and the actions that you can perform in this view.\n\nhttps://portal.nutanix.com/page/documents/details?targetId=Disaster-Recovery-DRaaS-Guide-vpc_2023_3:ecd-ecdr-az-ui-pc-r.html"}],"id":117},{"question":[{"txt":"Refer to Exhibit."},{"img":"1711472400410.png"},{"txt":"An administrator increases the cluster RF to 3. The containers are not modified.\nWhat will the new values in the data resiliency dashboard be for FAILURES TOLERABLE for the Zookeeper\nand Extent Groups components?"}],"options":["Zookeeper = 1 and Extent Groups = 1","Zookeeper = 2 and Extent Groups = 2","Zookeeper = 2 and Extent Groups = 1","Zookeeper = 1 and Extent Groups = 2"],"goodAnswer":[2],"explanations":[{"txt":"Lorsque le facteur de réplication (RF) est augmenté à 3, cela signifie qu'il y aura désormais trois copies de chaque bloc de données pour assurer la redondance et la résilience des données.\nPour les composants Zookeeper, qui sont critiques pour la gestion et la coordination du cluster, la valeur de \"FAILURES TOLERABLE\" sera égale à RF-1, donc dans ce cas, ce sera 3-1 = 2.\nPour les groupes d'extent, qui stockent les données réelles, la valeur de \"FAILURES TOLERABLE\" sera égale à RF-1, donc dans ce cas, ce sera 3-1 = 2.\nAinsi, la nouvelle valeur pour Zookeeper sera 2 et pour les groupes d'extent sera 1, ce qui correspond à l'option C."}],"id":118},{"question":[{"txt":"Which configurations scenarios are valid for the deployment of Prism Central? \n"}],"options":["Environments use Network Address Translation.","Prism Elements and Prism Central art in different subnets.","Environments do not have Internet access.","Prism Elements and Prism Central have proxy configured.","Environments use the 192.168.5.0/24 CVM management network."],"goodAnswer":[0,1,2,3,4],"explanations":[{"txt":"All the provided configuration scenarios are valid for the deployment of Prism Central. Here's why:\n\nA. Environments use Network Address Translation (NAT): Prism Central can be deployed in environments that use NAT. NAT is a common networking technique used to remap one IP address space into another by modifying network address information in the IP header of packets while in transit.\n\nB. Prism Elements and Prism Central are in different subnets: Prism Central can be deployed across different subnets as long as there is network connectivity and proper routing configured between them.\n\nC. Environments do not have Internet access: Prism Central can be deployed in environments without Internet access. It's a common requirement for many organizations to have isolated environments that do not have external Internet connectivity for security or compliance reasons.\n\nD. Prism Elements and Prism Central have proxy configured: Prism Central supports proxy configurations, allowing it to communicate through proxy servers if necessary to access external resources or for Internet connectivity.\n\nE. Environments use the 192.168.5.0/24 CVM management network: Prism Central can be deployed in environments using the specified CVM management network subnet (192.168.5.0/24) as long as there is proper network connectivity and routing between Prism Central and the managed CVMs.\n\nTherefore, all the provided configuration scenarios (A, B, C, D, and E) are valid for the deployment of Prism Central"}],"id":119}]